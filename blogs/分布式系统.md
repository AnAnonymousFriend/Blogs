---
title: 分布式架构学习笔记
date: 2024-3-11 10:57:00
tags: [计算机网络,学习笔记,分布式,微服务]
category: 系统设计
---

### 前言

时至今日单体架构已经是大多数开发者都实践过的一种软件架构，对于小型系统来说单台机器就足以良好运行，但对于工程师来说“大型单体系统”无疑是一个地狱：不可拓展，难以扩展，复杂逻辑难以调试，代码冲突让工程师们深陷其中。

如今流行的是“分布式系统”，“微服务”，“云原生”，“生成式AI”等新技术，这些技术随着时间的推移愈发成熟和稳定。想象之中，微服务架构对于程序员来说应该是友善的，你可以在这个架构体系下选择合适的技术栈，熟悉什么框架就使用什么框架。但是对于整个项目设计来说是复杂的，必然会面临“注册发现”，“负载均衡”，“熔断/降级”，“故障隔离”，“认证授权”，“通信传输”，“扩容”…… 等等问题。

Kubernetes 可能是解决上述问题的一个方案，“云原生”标准让更多的应用天生适合在云端部署，让无数工程师们趋之若鹜。Etcd 解决了注册发现的麻烦，容器化技术解决了故障隔离/扩容，“服务网格”不仅接管了应用所有对外通信，也对数据平面内的通信进行管理，无论是负载均衡还是通信传输，亦或者是熔断降级等。

笔者是从单体应用直接跨度到微服务架构应用的开发者，对于分布式架构系统一直存在疑虑，不得不承认对于分布式架构及微服务架构一直都没有一个系统的了解及分析，借此机会重新梳理。



### 共识算法

在分布式场景中，多个节点为了达成相同数据状态而运行的一种分布式算法。在分布式场景中可能会出现各种状况，例如网络丢包，时钟不一致，节点宕机，故障重启等造成数据状态不一致。共识算法需要容忍这些错误，并保证多个节点数据状态达成共识。

这里要注意，达成的不是一致性，而是共识。一致性是指不同数据副本之间的差异，而共识是指达成一致性的方法与过程。

#### Paxos

基于消息传递的协商共识算法。











### 事务处理

事务处理是分布式系统不可缺少的一部分，它的存在就是为了保证系统中所有的数据都是符合工程师预期的，即数据保持**一致性(Consistency)。**

原子性(Atomic)：事务保证对多个数据修改时，要么同时成功，要么同时失败。

隔离性(Isolation): 在不同的业务处理过程中，事务保证各自正在读写的数据相互独立，不会彼此影响。

持久性(Durability): 事务应该保证所有成功被提交的数据修改都能正确的被持久化，不丢失数据。

当一个服务只使用一个数据源时，获得一致性是相对容易的。因为多个并发的事务在读写时能感到是否存在冲突，并发事务的读写在时间线上的最终顺序是由数据源来确定的，这种事务间的一致性被称为“内部一致性”。

当使用多个数据源时，问题就会被放大多倍，不同服务并发写入多个不同数据源时，这些数据源可能在不同的机房，不同的城市，甚至不同的国家。确定时间顺序不由任何一个数据源来确定，在这种情况下“网络是不可信的”，“时钟是不可靠的”，“复制可能会延迟”，“部分数据可能会失效”……

解决上述问题会付出很大的代价，但是确实是分布式系统中必然会遇到的问题，所以对于架构师来说，在确保代价可承受的前提下尽可能保持一个较高的一致性保证。

在单体应用中我们可能不需要考虑这么多，最基础的同一数据源下事务解决方案是最基础的，但只适用于单个数据源头的场景，从代码层面上来说，工程师也不能深入到事务运行过程中。这些全都依赖底层的数据源提供支持。



#### TCC 事务

TCC是由"Try-Confirm-Cancel"三个单词的缩写，它是一种业务入侵较强的事务方案，要求业务处理过程必须拆分为"预留业务资源"和“确认/释放消费资源”两个子过程。TCC方案适用于需要强隔离性的分布式事务，比如解决"超售"问题：两个不同的用户在同一时间段内成功订购同一件商品，并且购买数量都不超过目前的库存，但购买数量之和却超过了库存。(使用消息队列无法保证避免"超售"情况出现)

Try: 尝试执行阶段，完成所有业务可执行性的检查(保障一致性)，并且预留好全部需用到业务资源(保障隔离性)。

Confirm: 确认执行阶段，不进行任何业务检查，直接使用Try阶段准备的资源来完成业务处理。Confirm 阶段可能会重复执行，因此本阶段所执行的操作需要具备幂等性。

Cancel: 取消执行阶段，释放Try阶段预留的业务资源。Cancel 阶段可能会重复执行，也需要满足幂等性。

TCC位于用户代码层，不在基础设施层面，在业务执行时只操作预留资源，几乎不会涉及锁和资源的争用。但是TCC会带来更高的开发成本和业务入侵，如果需求版本迭代场景发生变化时更改方案的成本也会愈高。所以如果需要实现TCC，可以基于某些分布式事务中间件来完成，这样会降低一部分的成本。





### 分布式缓存

对于分布式缓存来说，处理与网络相关的操作是对吞吐量影响更大的因素。

复制式缓存从理论上更适合少更新，频繁读的数据：缓存中所有数据在分布式集群的每个节点里面都存在一份副本，读数据时无需网络访问，直接从当前节点的内存中返回，理论上可以做到与进程内缓存一样高的读取性能。当数据发生变化时，必须遵从复制协议，将变更同步到集群的每个节点中，复制性能随着节点的增加呈现平方级下降，变更数据的代价十分高。

集中式缓存(目前分布式缓存主流形式)，读写都需要网络访问，优点是不会随着节点数量增加而产生额外的负担，缺点则是它不太可能达到进程内存中读写的高性能。

分布式缓存与进程内缓存各有所有，也各有局限，如果可以同时把进程内缓存和分布式缓存搭配，构建成透明多级缓存(Transparent Multilevel Cache,TMC)。但是这里要注意，这种方式代码侵入性太大，不方便管理，超时，刷新等策略需要设置多遍，更新数据也较为麻烦。常见的设计原则以变更分布式缓存中的数据为准，访问以进程内缓存的数据优先，如果数据发生变动，在集群内推送通知，当各个节点的一级缓存失效，当访问缓存时，提供一个封装好一，二级缓存联合的查询接口，外部节点只查询一次，接口内部自动实现优先查询一级缓存，未获取到数据再自动查询二级缓存。



#### 缓存穿透

缓存的目的是为了缓解CPU或者I/O的压力，如果有一类请求的流量每次都不会命中缓存内数据，这样每次都会触及到数据库，那么缓存就无法起到缓解压力的作用，这种情况叫做缓存穿透。

有两种办法可以解决缓存穿透：

1.如果业务逻辑本身无法避免缓存穿透，可以约定一定时间内返回为空的Key值进行缓存，这样在一段时间内缓存最多被穿透一次。

2.布隆过滤器，用最小代价判断某个元素是否存在某个集合的办法。如果依然判断为请求数据不存在，直接返回即可。



#### 缓存击穿

缓存中热点数据如果因为某些原因失效，同时又接收到多个针对该数据的请求，这些请求全部未能命中缓存，导致压力剧增。这种现象被称为缓存击穿。

有两种方式可以解决缓存击穿：

1.加锁同步，以请求该数据的Key值为锁，让第一个请求可以流入到真实的数据源中，其他线程阻塞或重试。如果是进程内缓存可以使用互斥锁，如果是分布式缓存则需要施加分布式锁，这样数据源不会同时收到大量针对一个数据的请求了。

2.手动管理，直接由工程师通过代码完成更新，失效，避免缓存策略自动管理。



#### 缓存雪崩

大批不同的数据在短时间内失效，导致这些数据请求击穿了缓存达到数据源，从而令数据源在短时间压力剧增。这种情况可能是冷操作加载的，还可能是缓存服务由某种故障崩溃后重启，这被称为缓存雪崩。

1.提升缓存系统可用性，设计分布式缓存的集群

2.使用透明多级缓存，各个服务器节点一级缓存中的数据通常加载时间不一样，分散它们的过期时间，避免同一时间内同时失效。

3.更改缓存的过期时间，改为一个随机时间。



#### 缓存污染

缓存污染是指缓存中数据与真实数据源中的数据不一致的现象。缓存污染大部分都是因为工程师更新缓存不规范造成的。更新缓存可以遵从设计模式：Cache Aside,Read/Write trough,Write Behind Caching等。





### 学习资源

[共识算法](https://docs.chainmaker.org.cn/tech/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95.html)

《凤凰架构》

