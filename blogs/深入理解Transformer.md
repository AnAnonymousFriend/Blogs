---
title: 深入理解Transformer自注意力机制
date: 2024-5-20 12:49:00
tags: [LLM,Transformer]
category: AI
---

### 前言

2017年，谷歌团队推出一篇神经网络的论文，首次提出将"自注意力"机制引入深度学习，这一机制可以按输入数据各部分重要性的不同而分配不同的权重。当ChatGPT震惊世人时，Transformer也随之进入大众视野。一夜之间，AI创业公司层出不穷，掌握算力的互联网寡头们争相推出自己的语言模型，这些模型或多或少都使用Transformer作为神经网络架构，比如ChatGPT只使用了其中的解码器。

而对于用户来说，大语言模型还是一个黑盒，用户只知道输入一些简单指令模型便会产生一些输出，这些输出可能满足用户的需求，也有可能不满足，于是用户通调整指令的方式来得到不同输出的结果，从笼统，抽象的概况到指令精确的下发，这也推进了提示词工程的发展。很难评论是机器在学习人类世界还是人类在适应机器，亦或都有。

开发者的世界中可能了解得更多，比如使用LangChain或LlamaIndex构建RAG(检索增强生成)系统，使用提示词工程优化输出结果，设置`temperature`等各类参数控制大模型创新性等……虽然比用户更接近黑盒，但依然存有很多无法解答的问题：为什么大语言模型会有上下文的限制？为什么现阶段的模型没有长期记忆？为什么要使用Transformer作为基础？

对于科学家来说上述问题可能很好回答，但大部分表述都是一些晦涩难懂的专有名词，谈论得更多的是向量化，嵌入层，归一化，矩阵等。本篇文章目的意在使用通俗语言解释这些专有名词，并通过数据流向的方式描绘“自注意力机制”在训练时的过程。





