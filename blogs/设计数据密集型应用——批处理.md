---
title: 《设计数据密集形应用》第三章读书笔记
date: 2023-8-15 16:47:00
tags: [分布式,学习笔记]
category: 分布式

---

# 批处理

《设计数据密集型应用》一书中的第三章第一小节告诉我们：不是所有服务都是**在线系统**的方式存在的，也会存在**离线系统**这一概念。即一个批处理系统，执行很多个Job来完成一些任务。这些任务通常会有大量的输入数据，根据不同的业务Job对数据进行处理，最终它会输出一些数据。这个过程往往需要一段时间，无需用户等待这些Job完成。

在介绍批处理系统前，开篇先谈论到Unix工具的批处理逻辑，继而引出 Unix 设计思想。

> Unix 管道的发明者道格・麦克罗伊（Doug McIlroy）在 1964 年首先描述了这种情况：“我们需要一种类似园艺胶管的方式来拼接程序 —— 当我们需要将消息从一个程序传递另一个程序时，直接接上去就行。I/O 应该也按照这种方式进行 ”。水管的类比仍然在生效，通过管道连接程序的想法成为了现在被称为 **Unix 哲学** 的一部分 —— 这一组设计原则在 Unix 用户与开发者之间流行起来，该哲学在 1978 年表述如下：
>
> 1. 让每个程序都做好一件事。要做一件新的工作，写一个新程序，而不是通过添加 “功能” 让老程序复杂化。
> 2. 期待每个程序的输出成为另一个程序的输入。不要将无关信息混入输出。避免使用严格的列数据或二进制输入格式。不要坚持交互式输入。
> 3. 设计和构建软件时，即使是操作系统，也让它们能够尽早地被试用，最好在几周内完成。不要犹豫，扔掉笨拙的部分，重建它们。
> 4. 优先使用工具来减轻编程任务，即使必须曲线救国编写工具，且在用完后很可能要扔掉大部分。

一般情况下，如果你希望一个程序的输出能够成为另一个程序的输入，那意味着这些程序必须使用相同的数据格式——或者是，一个兼容的接口。如果你希望能够将任何程序的输出连接到任何程序的输入，那意味着所有程序必须使用相同的 I/O 接口。

**Linux下一切皆文件**这句话也继承了Unix的哲学，在Unix中上述兼容的接口是一个**文件**，更准确来说是一个文件描述符。文件指示一串有序的字节序列。但是可以使用相同的接口来表示更多不同的东西：文件系统上的真实文件，到另一个进程的通信通道(Unix套接字等)，驱动程序等。

大部分Unix程序会将这个字节序列(这个接口，这个文件)视为ASCII文本。但是不是所有的。

几十年后重新审视这个设计，尽管它还不够完美，但是已经足够出色了。即使具有相同数据模型的数据库，将数据从一种数据库导出再导入到另一种数据库也并不容易。

Unix 工具的另一个特点是使用标准输入和标准输出。Unix 方法在程序不关心输入是从哪里而来，也不关心输出到哪里。工程师们可以将输入/输出与程序逻辑分开，使用各个小工具组成更大的系统。因为只要实现了接口，你可以自由编写程序将它们和操作系统提供的工具组合在一起。



### MapReduce 和分布式文件系统

MapReduce 像一个Unix工具，但是它分布在数千台机器上。作者评论它：相当的简单粗暴，但是令人惊异地管用。一个MapReduce作业和一个Unix进程类比：它接受一个或多个输入，产生一个或多个输出。

MapReduce 和 Unix 的区别在于，它在分布式文件系统上读写文件。

MapReduce 本质上是一个编程框架，我们可以使用它编写代码来处理分布式文件系统中的大型数据集。它有四个步骤：

1.读取一组输入文件，并将其分解成**记录**。(类似于服务器日志，一行日志就是一条记录)

2.调用Mapper函数，从每条输入记录中提取一对键值。(Mapper 函数可以由工程师们根据业务需求自由编写，例如你可以取日志中的某个信息当作键，并将值留空)

3.按键排序所有的键值对。

4.调用Reducer函数遍历排序后的键值对。如果同一个键出现多次，排列使它们在列表中相邻，所以很容易组合这些值而不必在内存中保留很多状态。

有经验的工程师看到上述四个步骤后很快就能明白，`Mapper`和`Reducer`函数是编写自定义数据处理代码的地方。Mapper 的作用就是从每条记录中提取键值，然后将它们放入到一个适合排序的表单中，同时它并不保存输入记录到下一个记录中的任何状态，可以说每条记录它都是独立处理的。而 Reducer的作用就是处理已排序的数据。

#### MapReduce中的分布式执行

MapReduce 可以在多台机器上并行执行计算，而无需编写代码来显式处理并行问题。本身Mapper 和Reducer 一次只能处理一条记录，它们也不在乎输入源和输出到什么地方，它本质就是一个无状态处理数据的工具，所以框架可以处理在机器之间移动数据的复杂性。

在分布式计算中，并行化基于分区，这意味着分布式批处理中的输出文件或文件快被认为是一个单独的分区。MapReduce 调度器会在其中一台存储输入文件副本的机器上运行每个Mapper。这个行为被称为**计算放在数据附近**，其实是为了节约网络复制输入文件的开销，减少网络复制并增加局部性。

计算的Reduce端也会被分区。虽然 Map 任务的数量由输入文件块的数量决定，但 Reducer 的任务的数量是由作业作者配置的。为了确保具有相同键的所有键值对最终落在相同的 Reducer 处，框架使用键的散列值来确定哪个 Reduce 任务应该接收到特定的键值对。

当Mapper读取输入文件，并写完排序后的输出文件，MapReduce调度器会通知Reducer获取输出文件。然后Reducer会按分区，排序，从 Mapper 向 Reducer 复制分区数据，这一整个过程被称为 **混洗（shuffle）**。然后将从Mapper获取的文件合并在一起，并保留有序特性，如果不同的Mapper生成了相同的键，则将它们相邻。

#### MapReduce工作流

单个MapReduce作业解决的问题范围很有限，所以在实际实际使用中将MapReduce作业链接为**工作流(workflow)**，一个作业的输出变为下一个作业的输入。Hadoop MapReduce 框架没有工作流的配置或设置，这个工作流的链是通过目录名隐式实现的。

只有当作业成功完成后，批处理作业的输出才会被视为有效的。这意味着作业之间存在依赖，有很多针对Hadoop的工作流调度器被开发出来。这些调度程序还具有管理功能，在维护大量批处理作业时非常有用。

#### 连接是如何实现的？

对于批处理，连接指的是在数据集中解析某种关联的全量存在。

实现某个业务需求的连接最简单的方法是：遍历事件，然后为其中的ID在远程服务器上查询数据库。但是它性能可能非常差，处理吞吐量将受限于数据库服务器的往返时间，本地缓存的有效性很大程度上取决于数据的分布，并行运行大量查询可能会轻易压垮数据库。

为了在批处理过程中实现良好的吞吐量，计算必须（尽可能）限于单台机器上进行。为待处理的每条记录发起随机访问的网络请求实在是太慢了。而且，查询远程数据库意味着批处理作业变为 **非确定的（nondeterministic）**，因为远程数据库中的数据可能会改变。

更好的办法是直接获取**连接**的目标数据库副本，然后全部放入同一个分布式文件系统中，比如你可以将用户数据库存储在一组文件中，而目标数据库存储在另一组文件中，并用MapReduce将所有相关记录集中在同一个地方进行高效处理。

Mapper会从每个输入记录中提取键值，通过框架对输出进行分区，然后对键值对进行排序，相同Key键在Reducer 输入中彼此相邻。 Map-Reduce 作业甚至可以也让这些记录排序，然后按照时间戳排序。这被称为**二次排序**。

Reducer 可以很容易执行实际的连接逻辑。它一次处理一个记录，所以只需要将记录保存在内存中就无需网络请求。这个算法被称为**排序合并连接**，因为 Mapper 的输出是按键排序的，然后 Reducer 将来自连接两侧的有序记录列表合并在一起。

Mapper和排序过程保证数据都必须放在同一个地方。使用MapReduce编程模型，能将计算的物理网络通信层面从应用逻辑中剥离出来。这种分离与数据库的用法形成了鲜明对比。Mapper处理了所有的网络通信，所以它也不用考虑一部分的分布式故障：例如另一个节点崩溃之类的。

#### 分组的实现

除了连接，将相关数据放在一起的另外一种模式就是：分组。比如SQL中的Group By 按照某个键进行分组。

使用 MapReduce 实现这种分组操作的最简单方法是设置 Mapper，以便它们生成的键值对使用所需的分组键。然后分区和排序过程将所有具有相同分区键的记录导向同一个 Reducer。因此在 MapReduce 之上实现分组和连接看上去非常相似。

分组还有一个常见用途是整理特定用户会话的所有活动事件，用于找出用户进行的一系列操作。

> 如果你有多个 Web 服务器处理用户请求，则特定用户的活动事件很可能分散在各个不同的服务器的日志文件中。你可以通过使用会话 cookie，用户 ID 或类似的标识符作为分组键，以将特定用户的所有活动事件放在一起来实现会话化，与此同时，不同用户的事件仍然散布在不同的分区中。



#### 处理偏斜

在现实生活中会存在与单个键关联的大量数据，比如社交平台中“关注”某个用户，这个用户往往存在大量的追随者。这种情况下“相同键的所有记录放在相同的位置”这种模式就被破坏了。这种不成比例的活动数据库记录被称为**关键对象或热键**。

单个Reducer中收集追随者众多的键可能导致严重的**偏斜**，这代表某个Reducer必须比其他Reducer处理更多的记录。由于 MapReduce 作业只有在所有 Mapper 和 Reducer 都完成时才完成，所有后续作业必须等待最慢的 Reducer 才能启动。

如果连续的输入存在热键，可以使用算法进行补偿。其中一种处理方法：

1.运行一个抽样作业判断哪些键是热键

2.连接实际执行时，Mapper 会将热键的关联记录 **随机**发送到几个 Reducer 之一

3.对于另外一侧的连接输入，与热键相关的记录需要被复制到 **所有** 处理该键的 Reducer 上

这种方式将处理热键的工作分散到多个Reducer上，这样就可以更好地并行化，代价是需要将连接另一侧的输入记录复制到多个 Reducer 上。 Crunch 中的 **分片连接（sharded join）** 方法与之类似，但需要显式指定热键而不是使用抽样作业。



#### Map侧连接

连接算法在 Reducer 中执行实际的连接逻辑，因此被称为 Reduce 侧连接。Mapper 扮演着预处理输入数据的角色：从每个输入记录中提取键值，将键值对分配给 Reducer 分区，并按键排序。

Reduce 侧方法的优点是不需要对输入数据做任何假设：无论其属性和结构如何，Mapper 都可以对其预处理以备连接。然而不利的一面是，排序，复制至 Reducer，以及合并 Reducer 输入，所有这些操作可能开销巨大。当数据通过 MapReduce 阶段时，数据可能需要落盘好几次，取决于可用的内存缓冲区。

但是如果能对输入数据作出某种假设，则通过使用所谓的 Map 侧连接来加快连接速度是可行的。这种方法使用了一个裁减掉 Reducer 与排序的 MapReduce 作业，每个 Mapper 只是简单地从分布式文件系统中读取一个输入文件块，然后将输出文件写入文件系统，仅此而已。

##### 广播散列连接

适用于执行 Map 端连接的最简单场景是大数据集与小数据集连接的情况。要点在于小数据集需要足够小，以便可以将其全部加载到每个 Mapper 的内存中。

如果用户数据库小到足以放进内存中，当Mapper启动时，它可以将用户数据库从分布式文件系统读取到内存中的散列表。Mapper 可以扫描用户活动事件，然后简单在散列表中查找每个事件的用户ID。

那么什么是**广播散列连接**？

每个连接较大输入端分区的 Mapper 都会将较小输入端数据集整个读入内存中，这叫做广播。而散列意味着使用散列表。

另一种方法是将较小输入存储在本地磁盘上的只读索引中。索引中经常使用的部分将保留在操作系统的页面缓存中，因而这种方法可以提供与内存散列表几乎一样快的随机查找性能，但实际上并不需要数据集能放入内存中。

**分区情况下**

如果 Map 侧连接的输入以相同的方式进行分区，则散列连接方法可以独立应用于每个分区。

> 如果分区正确无误，可以确定的是，所有你可能需要连接的记录都落在同一个编号的分区中。因此每个 Mapper 只需要从输入两端各读取一个分区就足够了。好处是每个 Mapper 都可以在内存散列表中少放点数据。
>
> 这种方法只有当连接两端输入有相同的分区数，且两侧的记录都是使用相同的键与相同的哈希函数做分区时才适用。如果输入是由之前执行过这种分组的 MapReduce 作业生成的，那么这可能是一个合理的假设。
>
> 分区散列连接在 Hive 中称为 **Map 侧桶连接（bucketed map joins）**

有一些方案属于Map侧连接的变体，比如输入的数据集不仅以相同的方式进行分区，而且还基于相同的键进行**排序**。在这种情况下，数据集能不能放在内存中反倒不重要了因为这个情况下Mapper同样可以执行并归操作(按键递增的顺序依次读取两个输入文件，将具有相同键的记录配对)。

如果能进行Map侧合并连接，这意味着前一个MapReduce作业可能一开始就把输入数据做了分区并排序。

当下游作业使用 MapReduce 连接的输出时，选择 Map 侧连接或 Reduce 侧连接会影响输出的结构。

在优化连接策略时，了解分布式文件系统中数据集的物理布局变得非常重要：仅仅知道编码格式和数据存储目录的名称是不够的；你还必须知道数据是按哪些键做的分区和排序，以及分区的数量。



#### 批处理的输出

批处理的输出通常不是报表，而是一些其他类型的结构。

比如**建立搜索索引**，谷歌最开始就是这样做的，使用MapReduce 为搜索引擎建立索引，由多个MapReduce作业组成的工作流。时至今日，使用MapReduce依旧是构建索引的优选方案。

但是要注意，索引文件一旦创建就是不可变的。如果索引的文档集合发生改变，这代表我们要定期重跑整个索引工作流，然后批量替换以前的索引文件。如果只有少量索引文件需要更改，这种方案就会让计算成本变得很高，且频繁。

在上述基础上，可以使用**增量建立索引**，如果要在索引中添加，删除或更新文档，Lucene 会写新的段文件，并在后台异步合并压缩段文件。

总而言之，批处理的输出应该如何回到应用可以查询的数据库中呢？

1.直接在Mapper或Reducer中直接写入数据库服务器，但是会造成几个问题：

- 性能差：为每条记录,发起数据库网络请求要比正常处理任务要慢得多;
- 并行处理任务时，数量级太大可能会压垮数据库;
- 工作流任务可能存在执行失败，这需要工程师自己维护后续造成的影响

2.创建一个新的数据库，将这个数据库作为文件写入分布式文件系统中作业的输出目录。这些数据文件一旦写入就是不可变的，可以批量加载到处理只读查询的服务器中。不少键值存储都支持在 MapReduce 作业中构建数据库文件。

> 程序读取输入并写入输出。在这一过程中，输入保持不变，任何先前的输出都被新输出完全替换，且没有其他副作用。这意味着你可以随心所欲地重新运行一个命令，略做改动或进行调试，而不会搅乱系统的状态。

上述设计哲学在MapReduce作用输出的时候也同样体现：

1.作业可以随时重新运行，根据输出结果来矫正代码。但是要注意，如果部署了数据库，回滚代码也无法修复数据库中的数据。

2.由于回滚很容易，比起在错误意味着不可挽回的伤害的环境，功能开发进展能快很多。这种 **最小化不可逆性（minimizing irreversibility）** 的原则有利于敏捷软件开发

3.如果 Map 或 Reduce 任务失败，MapReduce 框架将自动重新调度，并在同样的输入上再次运行它。如果失败是由代码中的错误造成的，那么它会不断崩溃，并最终导致作业在几次尝试之后失败。但是如果故障是由于临时问题导致的，那么故障就会被容忍。因为输入不可变，这种自动重试是安全的，而失败任务的输出会被 MapReduce 框架丢弃。

4.同一组文件可用作各种不同作业的输入，包括计算指标的监控作业并且评估作业的输出是否具有预期的性质（例如，将其与前一次运行的输出进行比较并测量差异） 。

5.与 Unix 工具类似，MapReduce 作业将逻辑与布线（配置输入和输出目录）分离，这使得关注点分离，可以重用代码：一个团队可以专注实现一个做好一件事的作业；而其他团队可以决定何时何地运行这项作业。



### Hadoop与分布式数据库的对比

数据库专注在一组机器上并行执行SQL查询，而 MapReduce 和分布式文件系统的组合则更像是一个可以运行任意程序的通用操作系统。

**在存储方面**：

数据库会限制数据库模型(比如关系或文档)来构建数据，而分布式文件系统中的文件只是**字节序列**。

> 将大型组织的各个部分的数据集中在一起是很有价值的，因为它可以跨越以前相互分离的数据集进行连接。 MPP 数据库所要求的谨慎模式设计拖慢了集中式数据收集速度；以原始形式收集数据，稍后再操心模式的设计，能使数据收集速度加快（有时被称为 “**数据湖（data lake）**” 或 “**企业数据中心（enterprise data hub）**”）
>
> 不加区分的数据转储转移了解释数据的负担：数据集的生产者不再需要强制将其转化为标准格式，数据的解释成为消费者的问题。
>
> 如果生产者和消费者是不同优先级的不同团队，这可能是一种优势。甚至可能不存在一个理想的数据模型，对于不同目的有不同的合适视角。以原始形式简单地转储数据，可以允许多种这样的转换。这种方法被称为 **寿司原则（sushi principle）**：“原始数据更好”。

**处理模型时的多样性：**

数据库需要根据不同领域来进行数据模型的更替，比如推荐系统的模型或机器学习，同时又不是所有类型的处理都可以合理表达为SQL查询。这些类型的处理通常是特别针对特定应用的，所以必须要编写代码来处理，而不仅仅是查询这一项。

> MapReduce 使工程师能够轻松地在大型数据集上运行自己的代码。如果你有 HDFS 和 MapReduce，那么你 **可以** 在它之上建立一个 SQL 查询执行引擎，事实上这正是 Hive 项目所做的。但是，你也可以编写许多其他形式的批处理，这些批处理不必非要用 SQL 查询表示。
>
> 随后，人们发现 MapReduce 对于某些类型的处理而言局限性很大，表现很差，因此在 Hadoop 之上其他各种处理模型也被开发出来（我们将在 “[MapReduce 之后](https://github.com/Vonng/ddia/blob/master/ch10.md#MapReduce之后)” 中看到其中一些）。只有两种处理模型，SQL 和 MapReduce，还不够，需要更多不同的模型！而且由于 Hadoop 平台的开放性，实施一整套方法是可行的，而这在单体 MPP 数据库的范畴内是不可能的。
>
> 至关重要的是，这些不同的处理模型都可以在共享的单个机器集群上运行，所有这些机器都可以访问分布式文件系统上的相同文件。在 Hadoop 方式中，不需要将数据导入到几个不同的专用系统中进行不同类型的处理：系统足够灵活，可以支持同一个集群内不同的工作负载。不需要移动数据，使得从数据中挖掘价值变得容易得多，也使采用新的处理模型容易的多。
>
> Hadoop 生态系统包括随机访问的 OLTP 数据库，如 HBase（请参阅 “[SSTables 和 LSM 树](https://github.com/Vonng/ddia/blob/master/ch3.md#SSTables和LSM树)”）和 MPP 风格的分析型数据库，如 Impala 。 HBase 与 Impala 都不使用 MapReduce，但都使用 HDFS 进行存储。它们是迥异的数据访问与处理方法，但是它们可以共存，并被集成到同一个系统中。

**处理故障：**

批处理系统可能对处理故障不太敏感，因为就算失败了也不会影响某个用户，只需要再次执行一遍即可。

但是大部分数据库会中止，并且选择让用户来判断是否要重新提交执行，或通过预设自动重新运行它。由于查询通常最多运行几秒钟或几分钟，所以这种错误处理的方法是可以接受的，因为重试的代价不是太大。 MPP 数据库还倾向于在内存中保留尽可能多的数据以避免从磁盘读取的开销。

MapReduce 可以容忍单个 Map 或 Reduce 任务的失败，而不会影响作业的整体，通过以单个任务的粒度重试工作。它也会非常急切地将数据写入磁盘，一方面是为了容错，另一部分是因为假设数据集太大而不能适应内存。

MapReduce 方式更适用于较大的作业：要处理如此之多的数据并运行很长时间的作业，以至于在此过程中很可能至少遇到一个任务故障。在这种情况下，由于单个任务失败而重新运行整个作业将是非常浪费的。即使以单个任务的粒度进行恢复引入了使得无故障处理更慢的开销，但如果任务失败率足够高，这仍然是一种合理的权衡。



> MapReduce 只是分布式系统的许多可能的编程模型之一。

#### 物化中间状态

> 但在很多情况下，你知道一个作业的输出只能用作另一个作业的输入，这些作业由同一个团队维护。在这种情况下，分布式文件系统上的文件只是简单的 **中间状态（intermediate state）**：一种将数据从一个作业传递到下一个作业的方式。在一个用于构建推荐系统的，由 50 或 100 个 MapReduce 作业组成的复杂工作流中，存在着很多这样的中间状态。
>
> 将这个中间状态写入文件的过程称为 **物化（materialization）**。 

MapReduce 完全物化中间状态的方法存在不足之处：

- MapReduce 作业只有在前驱作业（生成其输入）中的所有任务都完成时才能启动，而由 Unix 管道连接的进程会同时启动，输出一旦生成就会被消费。不同机器上的数据偏斜或负载不均意味着一个作业往往会有一些掉队的任务，比其他任务要慢得多才能完成。必须等待至前驱作业的所有任务完成，拖慢了整个工作流程的执行。
- Mapper 通常是多余的：它们仅仅是读取刚刚由 Reducer 写入的同样文件，为下一个阶段的分区和排序做准备。在许多情况下，Mapper 代码可能是前驱 Reducer 的一部分：如果 Reducer 和 Mapper 的输出有着相同的分区与排序方式，那么 Reducer 就可以直接串在一起，而不用与 Mapper 相互交织。
- 将中间状态存储在分布式文件系统中意味着这些文件被复制到多个节点，对这些临时数据这么搞就比较过分了。

为了解决上述问题，几种用于分布式批处理的新执行引擎在设计时会有一个共同点：将整个工作流作为单个作业来处理，而不是把它分解为独立的子作业。

由于它们将工作流显式建模为数据从几个处理阶段穿过，所以这些系统被称为 **数据流引擎（dataflow engines）**。像 MapReduce 一样，它们在一条线上通过反复调用用户定义的函数来一次处理一条记录，它们通过输入分区来并行化载荷，它们通过网络将一个函数的输出复制到另一个函数的输入。

与 MapReduce 不同，这些函数不需要严格扮演交织的 Map 与 Reduce 的角色，而是可以以更灵活的方式进行组合。我们称这些函数为 **算子（operators）**，数据流引擎提供了几种不同的选项来将一个算子的输出连接到另一个算子的输入。

1.对记录按照键重新分区并排序，用于实现排序合并连接和分组

2.接受多个输入，然后使用同一种方式进行分区，但是不排序。这种情况适用于分区重要但顺序无关紧要。

3.对于广播散列连接，可以将一个算子的输出，发送到连接算子的所有分区

这样做的优点是：

- 排序这种昂贵的工作只需要在实际需要的地方执行，不需要默认在Map或者Reduce阶段中实现
- Mapper的工作可以合并在上一个 Reduce 算子中
- 方便调度，数据可以通过共享内存缓冲区传输，不需要通过网络复制数据
- 算子可以在输入就绪后立即开始执行；后续阶段无需等待前驱阶段整个完成后再开始。

数据流引擎执行与 MapReduce 工作流同样的计算，根据上述优化，通常执行速度要明显快得多。



#### 容错

> 完全物化中间状态至分布式文件系统的一个优点是，它具有持久性，这使得 MapReduce 中的容错相当容易：如果一个任务失败，它可以在另一台机器上重新启动，并从文件系统重新读取相同的输入。

如果一台机器上发生故障，并且该机器上的中间状态丢失，则它回从其他仍然可用的数据重新计算。但是要注意，这种处理方式要求“算子”是确定性的，输入同样的数据集那么它们经过算子处理后的数据一定是相同的。工程师需要消除算子中存在的不稳定性，比如禁止使用随机数，系统时钟等。

通过重算数据来从故障中恢复并不总是正确的答案：如果中间状态数据要比源数据小得多，或者如果计算量非常大，那么将中间数据物化为文件可能要比重新计算廉价的多。

> MapReduce 就像是将每个命令的输出写入临时文件，而数据流引擎看起来更像是 Unix 管道。



手写MapReduce作业可能是个苦力活，随着技术发展，一些高级语言可以迁移到新的数据流执行引擎，而无需重写作业代码。但是本人没有这方面的编程经验，更适合的可能是通过数据流API来进行实践，通过某些通用的接口来完成这部分的拓展和工作，这倒也符合 Unix 的哲学。

> MapReduce 是围绕着回调函数的概念建立的：对于每条记录或者一组记录，调用一个用户定义的函数（Mapper 或 Reducer），并且该函数可以自由地调用任意代码来决定输出什么。这种方法的优点是可以基于大量已有库的生态系统创作：解析、自然语言分析、图像分析以及运行数值或统计算法等。
>
> 自由运行任意代码，长期以来都是传统 MapReduce 批处理系统与 MPP 数据库的区别所在。

批处理系统在机器学习或推荐系统，分类器等领域可能更实用。

批处理引擎正被用于分布式执行日益广泛的各领域算法。随着批处理系统获得各种内置功能以及高级声明式算子，且随着 MPP 数据库变得更加灵活和易于编程，两者开始看起来相似了：最终，它们都只是存储和处理数据的系统。



### 本章小结

本章中讨论了批处理系统，从Unix工具开始延伸，再到MapReduce框架实现原理和过程，以及分布式中批处理面对分区，容错等方面的处理，最后到探讨批处理系统的发展。

得益于这个框架，在处理批处理作业时不需要担心实现容错机制，上述原理也向我们证明了批处理系统的可靠性。

> 分布式批处理引擎有一个刻意限制的编程模型：回调函数（比如 Mapper 和 Reducer）被假定是无状态的，而且除了指定的输出外，必须没有任何外部可见的副作用。这一限制允许框架在其抽象下隐藏一些困难的分布式系统问题：当遇到崩溃和网络问题时，任务可以安全地重试，任何失败任务的输出都被丢弃。如果某个分区的多个任务成功，则其中只有一个能使其输出实际可见。
>
> 批处理作业的显著特点是，它读取一些输入数据并产生一些输出数据，但不修改输入 —— 换句话说，输出是从输入衍生出的。最关键的是，输入数据是 **有界的（bounded）**：它有一个已知的，固定的大小（例如，它包含一些时间点的日志文件或数据库内容的快照）。因为它是有界的，一个作业知道自己什么时候完成了整个输入的读取，所以一个工作在做完后，最终总是会完成的。
