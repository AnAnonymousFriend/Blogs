---
title: 《设计数据密集形应用》第三章读书笔记
date: 2023-8-15 16:47:00
tags: [分布式,学习笔记]
category: 分布式

---

# 批处理

《设计数据密集型应用》一书中的第三章第一小节告诉我们：不是所有服务都是**在线系统**的方式存在的，也会存在**离线系统**这一概念。即一个批处理系统，执行很多个Job来完成一些任务。这些任务通常会有大量的输入数据，根据不同的业务Job对数据进行处理，最终它会输出一些数据。这个过程往往需要一段时间，无需用户等待这些Job完成。

在介绍批处理系统前，开篇先谈论到Unix工具的批处理逻辑，继而引出 Unix 设计思想。

> Unix 管道的发明者道格・麦克罗伊（Doug McIlroy）在 1964 年首先描述了这种情况：“我们需要一种类似园艺胶管的方式来拼接程序 —— 当我们需要将消息从一个程序传递另一个程序时，直接接上去就行。I/O 应该也按照这种方式进行 ”。水管的类比仍然在生效，通过管道连接程序的想法成为了现在被称为 **Unix 哲学** 的一部分 —— 这一组设计原则在 Unix 用户与开发者之间流行起来，该哲学在 1978 年表述如下：
>
> 1. 让每个程序都做好一件事。要做一件新的工作，写一个新程序，而不是通过添加 “功能” 让老程序复杂化。
> 2. 期待每个程序的输出成为另一个程序的输入。不要将无关信息混入输出。避免使用严格的列数据或二进制输入格式。不要坚持交互式输入。
> 3. 设计和构建软件时，即使是操作系统，也让它们能够尽早地被试用，最好在几周内完成。不要犹豫，扔掉笨拙的部分，重建它们。
> 4. 优先使用工具来减轻编程任务，即使必须曲线救国编写工具，且在用完后很可能要扔掉大部分。

一般情况下，如果你希望一个程序的输出能够成为另一个程序的输入，那意味着这些程序必须使用相同的数据格式——或者是，一个兼容的接口。如果你希望能够将任何程序的输出连接到任何程序的输入，那意味着所有程序必须使用相同的 I/O 接口。

**Linux下一切皆文件**这句话也继承了Unix的哲学，在Unix中上述兼容的接口是一个**文件**，更准确来说是一个文件描述符。文件指示一串有序的字节序列。但是可以使用相同的接口来表示更多不同的东西：文件系统上的真实文件，到另一个进程的通信通道(Unix套接字等)，驱动程序等。

大部分Unix程序会将这个字节序列(这个接口，这个文件)视为ASCII文本。但是不是所有的。

几十年后重新审视这个设计，尽管它还不够完美，但是已经足够出色了。即使具有相同数据模型的数据库，将数据从一种数据库导出再导入到另一种数据库也并不容易。

Unix 工具的另一个特点是使用标准输入和标准输出。Unix 方法在程序不关心输入是从哪里而来，也不关心输出到哪里。工程师们可以将输入/输出与程序逻辑分开，使用各个小工具组成更大的系统。因为只要实现了接口，你可以自由编写程序将它们和操作系统提供的工具组合在一起。



### MapReduce 和分布式文件系统

MapReduce 像一个Unix工具，但是它分布在数千台机器上。作者评论它：相当的简单粗暴，但是令人惊异地管用。一个MapReduce作业和一个Unix进程类比：它接受一个或多个输入，产生一个或多个输出。

MapReduce 和 Unix 的区别在于，它在分布式文件系统上读写文件。

MapReduce 本质上是一个编程框架，我们可以使用它编写代码来处理分布式文件系统中的大型数据集。它有四个步骤：

1.读取一组输入文件，并将其分解成**记录**。(类似于服务器日志，一行日志就是一条记录)

2.调用Mapper函数，从每条输入记录中提取一对键值。(Mapper 函数可以由工程师们根据业务需求自由编写，例如你可以取日志中的某个信息当作键，并将值留空)

3.按键排序所有的键值对。

4.调用Reducer函数遍历排序后的键值对。如果同一个键出现多次，排列使它们在列表中相邻，所以很容易组合这些值而不必在内存中保留很多状态。

有经验的工程师看到上述四个步骤后很快就能明白，`Mapper`和`Reducer`函数是编写自定义数据处理代码的地方。Mapper 的作用就是从每条记录中提取键值，然后将它们放入到一个适合排序的表单中，同时它并不保存输入记录到下一个记录中的任何状态，可以说每条记录它都是独立处理的。而 Reducer的作用就是处理已排序的数据。

#### MapReduce中的分布式执行

MapReduce 可以在多台机器上并行执行计算，而无需编写代码来显式处理并行问题。本身Mapper 和Reducer 一次只能处理一条记录，它们也不在乎输入源和输出到什么地方，它本质就是一个无状态处理数据的工具，所以框架可以处理在机器之间移动数据的复杂性。

在分布式计算中，并行化基于分区，这意味着分布式批处理中的输出文件或文件快被认为是一个单独的分区。MapReduce 调度器会在其中一台存储输入文件副本的机器上运行每个Mapper。这个行为被称为**计算放在数据附近**，其实是为了节约网络复制输入文件的开销，减少网络复制并增加局部性。

计算的Reduce端也会被分区。虽然 Map 任务的数量由输入文件块的数量决定，但 Reducer 的任务的数量是由作业作者配置的。为了确保具有相同键的所有键值对最终落在相同的 Reducer 处，框架使用键的散列值来确定哪个 Reduce 任务应该接收到特定的键值对。

当Mapper读取输入文件，并写完排序后的输出文件，MapReduce调度器会通知Reducer获取输出文件。然后Reducer会按分区，排序，从 Mapper 向 Reducer 复制分区数据，这一整个过程被称为 **混洗（shuffle）**。然后将从Mapper获取的文件合并在一起，并保留有序特性，如果不同的Mapper生成了相同的键，则将它们相邻。

#### MapReduce工作流

单个MapReduce作业解决的问题范围很有限，所以在实际实际使用中将MapReduce作业链接为**工作流(workflow)**，一个作业的输出变为下一个作业的输入。Hadoop MapReduce 框架没有工作流的配置或设置，这个工作流的链是通过目录名隐式实现的。

只有当作业成功完成后，批处理作业的输出才会被视为有效的。这意味着作业之间存在依赖，有很多针对Hadoop的工作流调度器被开发出来。这些调度程序还具有管理功能，在维护大量批处理作业时非常有用。

#### 连接是如何实现的？

对于批处理，连接指的是在数据集中解析某种关联的全量存在。

实现某个业务需求的连接最简单的方法是：遍历事件，然后为其中的ID在远程服务器上查询数据库。但是它性能可能非常差，处理吞吐量将受限于数据库服务器的往返时间，本地缓存的有效性很大程度上取决于数据的分布，并行运行大量查询可能会轻易压垮数据库。

为了在批处理过程中实现良好的吞吐量，计算必须（尽可能）限于单台机器上进行。为待处理的每条记录发起随机访问的网络请求实在是太慢了。而且，查询远程数据库意味着批处理作业变为 **非确定的（nondeterministic）**，因为远程数据库中的数据可能会改变。

更好的办法是直接获取**连接**的目标数据库副本，然后全部放入同一个分布式文件系统中，比如你可以将用户数据库存储在一组文件中，而目标数据库存储在另一组文件中，并用MapReduce将所有相关记录集中在同一个地方进行高效处理。

Mapper会从每个输入记录中提取键值，通过框架对输出进行分区，然后对键值对进行排序，相同Key键在Reducer 输入中彼此相邻。 Map-Reduce 作业甚至可以也让这些记录排序，然后按照时间戳排序。这被称为**二次排序**。

Reducer 可以很容易执行实际的连接逻辑。它一次处理一个记录，所以只需要将记录保存在内存中就无需网络请求。这个算法被称为**排序合并连接**，因为 Mapper 的输出是按键排序的，然后 Reducer 将来自连接两侧的有序记录列表合并在一起。

Mapper和排序过程保证数据都必须放在同一个地方。使用MapReduce编程模型，能将计算的物理网络通信层面从应用逻辑中剥离出来。这种分离与数据库的用法形成了鲜明对比。Mapper处理了所有的网络通信，所以它也不用考虑一部分的分布式故障：例如另一个节点崩溃之类的。

#### 分组的实现

除了连接，将相关数据放在一起的另外一种模式就是：分组。比如SQL中的Group By 按照某个键进行分组。

使用 MapReduce 实现这种分组操作的最简单方法是设置 Mapper，以便它们生成的键值对使用所需的分组键。然后分区和排序过程将所有具有相同分区键的记录导向同一个 Reducer。因此在 MapReduce 之上实现分组和连接看上去非常相似。

分组还有一个常见用途是整理特定用户会话的所有活动事件，用于找出用户进行的一系列操作。

> 如果你有多个 Web 服务器处理用户请求，则特定用户的活动事件很可能分散在各个不同的服务器的日志文件中。你可以通过使用会话 cookie，用户 ID 或类似的标识符作为分组键，以将特定用户的所有活动事件放在一起来实现会话化，与此同时，不同用户的事件仍然散布在不同的分区中。



#### 处理偏斜

在现实生活中会存在与单个键关联的大量数据，比如社交平台中“关注”某个用户，这个用户往往存在大量的追随者。这种情况下“相同键的所有记录放在相同的位置”这种模式就被破坏了。这种不成比例的活动数据库记录被称为**关键对象或热键**。

单个Reducer中收集追随者众多的键可能导致严重的**偏斜**，这代表某个Reducer必须比其他Reducer处理更多的记录。由于 MapReduce 作业只有在所有 Mapper 和 Reducer 都完成时才完成，所有后续作业必须等待最慢的 Reducer 才能启动。

如果连续的输入存在热键，可以使用算法进行补偿。其中一种处理方法：

1.运行一个抽样作业判断哪些键是热键

2.连接实际执行时，Mapper 会将热键的关联记录 **随机**发送到几个 Reducer 之一

3.对于另外一侧的连接输入，与热键相关的记录需要被复制到 **所有** 处理该键的 Reducer 上

这种方式将处理热键的工作分散到多个Reducer上，这样就可以更好地并行化，代价是需要将连接另一侧的输入记录复制到多个 Reducer 上。 Crunch 中的 **分片连接（sharded join）** 方法与之类似，但需要显式指定热键而不是使用抽样作业。



#### Map侧连接

连接算法在 Reducer 中执行实际的连接逻辑，因此被称为 Reduce 侧连接。Mapper 扮演着预处理输入数据的角色：从每个输入记录中提取键值，将键值对分配给 Reducer 分区，并按键排序。

Reduce 侧方法的优点是不需要对输入数据做任何假设：无论其属性和结构如何，Mapper 都可以对其预处理以备连接。然而不利的一面是，排序，复制至 Reducer，以及合并 Reducer 输入，所有这些操作可能开销巨大。当数据通过 MapReduce 阶段时，数据可能需要落盘好几次，取决于可用的内存缓冲区。

但是如果能对输入数据作出某种假设，则通过使用所谓的 Map 侧连接来加快连接速度是可行的。这种方法使用了一个裁减掉 Reducer 与排序的 MapReduce 作业，每个 Mapper 只是简单地从分布式文件系统中读取一个输入文件块，然后将输出文件写入文件系统，仅此而已。

##### 广播散列连接

适用于执行 Map 端连接的最简单场景是大数据集与小数据集连接的情况。要点在于小数据集需要足够小，以便可以将其全部加载到每个 Mapper 的内存中。

如果用户数据库小到足以放进内存中，当Mapper启动时，它可以将用户数据库从分布式文件系统读取到内存中的散列表。Mapper 可以扫描用户活动事件，然后简单在散列表中查找每个事件的用户ID。

那么什么是**广播散列连接**？

每个连接较大输入端分区的 Mapper 都会将较小输入端数据集整个读入内存中，这叫做广播。而散列意味着使用散列表。

另一种方法是将较小输入存储在本地磁盘上的只读索引中。索引中经常使用的部分将保留在操作系统的页面缓存中，因而这种方法可以提供与内存散列表几乎一样快的随机查找性能，但实际上并不需要数据集能放入内存中。

**分区情况下**

如果 Map 侧连接的输入以相同的方式进行分区，则散列连接方法可以独立应用于每个分区。

> 如果分区正确无误，可以确定的是，所有你可能需要连接的记录都落在同一个编号的分区中。因此每个 Mapper 只需要从输入两端各读取一个分区就足够了。好处是每个 Mapper 都可以在内存散列表中少放点数据。
>
> 这种方法只有当连接两端输入有相同的分区数，且两侧的记录都是使用相同的键与相同的哈希函数做分区时才适用。如果输入是由之前执行过这种分组的 MapReduce 作业生成的，那么这可能是一个合理的假设。
>
> 分区散列连接在 Hive 中称为 **Map 侧桶连接（bucketed map joins）**

