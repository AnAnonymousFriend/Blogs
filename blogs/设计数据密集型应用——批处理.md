---
title: 《设计数据密集形应用》第三章读书笔记
date: 2023-8-15 16:47:00
tags: [分布式,学习笔记]
category: 分布式

---

# 批处理

《设计数据密集型应用》一书中的第三章第一小节告诉我们：不是所有服务都是**在线系统**的方式存在的，也会存在**离线系统**这一概念。即一个批处理系统，执行很多个Job来完成一些任务。这些任务通常会有大量的输入数据，根据不同的业务Job对数据进行处理，最终它会输出一些数据。这个过程往往需要一段时间，无需用户等待这些Job完成。

在介绍批处理系统前，开篇先谈论到Unix工具的批处理逻辑，继而引出 Unix 设计思想。

> Unix 管道的发明者道格・麦克罗伊（Doug McIlroy）在 1964 年首先描述了这种情况：“我们需要一种类似园艺胶管的方式来拼接程序 —— 当我们需要将消息从一个程序传递另一个程序时，直接接上去就行。I/O 应该也按照这种方式进行 ”。水管的类比仍然在生效，通过管道连接程序的想法成为了现在被称为 **Unix 哲学** 的一部分 —— 这一组设计原则在 Unix 用户与开发者之间流行起来，该哲学在 1978 年表述如下：
>
> 1. 让每个程序都做好一件事。要做一件新的工作，写一个新程序，而不是通过添加 “功能” 让老程序复杂化。
> 2. 期待每个程序的输出成为另一个程序的输入。不要将无关信息混入输出。避免使用严格的列数据或二进制输入格式。不要坚持交互式输入。
> 3. 设计和构建软件时，即使是操作系统，也让它们能够尽早地被试用，最好在几周内完成。不要犹豫，扔掉笨拙的部分，重建它们。
> 4. 优先使用工具来减轻编程任务，即使必须曲线救国编写工具，且在用完后很可能要扔掉大部分。

一般情况下，如果你希望一个程序的输出能够成为另一个程序的输入，那意味着这些程序必须使用相同的数据格式——或者是，一个兼容的接口。如果你希望能够将任何程序的输出连接到任何程序的输入，那意味着所有程序必须使用相同的 I/O 接口。

**Linux下一切皆文件**这句话也继承了Unix的哲学，在Unix中上述兼容的接口是一个**文件**，更准确来说是一个文件描述符。文件指示一串有序的字节序列。但是可以使用相同的接口来表示更多不同的东西：文件系统上的真实文件，到另一个进程的通信通道(Unix套接字等)，驱动程序等。

大部分Unix程序会将这个字节序列(这个接口，这个文件)视为ASCII文本。但是不是所有的。

几十年后重新审视这个设计，尽管它还不够完美，但是已经足够出色了。即使具有相同数据模型的数据库，将数据从一种数据库导出再导入到另一种数据库也并不容易。

Unix 工具的另一个特点是使用标准输入和标准输出。Unix 方法在程序不关心输入是从哪里而来，也不关心输出到哪里。工程师们可以将输入/输出与程序逻辑分开，使用各个小工具组成更大的系统。因为只要实现了接口，你可以自由编写程序将它们和操作系统提供的工具组合在一起。



### MapReduce 和分布式文件系统

MapReduce 像一个Unix工具，但是它分布在数千台机器上。作者评论它：相当的简单粗暴，但是令人惊异地管用。一个MapReduce作业和一个Unix进程类比：它接受一个或多个输入，产生一个或多个输出。

MapReduce 和 Unix 的区别在于，它在分布式文件系统上读写文件。

MapReduce 本质上是一个编程框架，我们可以使用它编写代码来处理分布式文件系统中的大型数据集。它有四个步骤：

1.读取一组输入文件，并将其分解成**记录**。(类似于服务器日志，一行日志就是一条记录)

2.调用Mapper函数，从每条输入记录中提取一对键值。(Mapper 函数可以由工程师们根据业务需求自由编写，例如你可以取日志中的某个信息当作键，并将值留空)

3.按键排序所有的键值对。

4.调用Reducer函数遍历排序后的键值对。如果同一个键出现多次，排列使它们在列表中相邻，所以很容易组合这些值而不必在内存中保留很多状态。

有经验的工程师看到上述四个步骤后很快就能明白，`Mapper`和`Reducer`函数是编写自定义数据处理代码的地方。Mapper 的作用就是从每条记录中提取键值，然后将它们放入到一个适合排序的表单中，同时它并不保存输入记录到下一个记录中的任何状态，可以说每条记录它都是独立处理的。而 Reducer的作用就是处理已排序的数据。

#### MapReduce中的分布式执行

MapReduce 可以在多台机器上并行执行计算，而无需编写代码来显式处理并行问题。本身Mapper 和Reducer 一次只能处理一条记录，它们也不在乎输入源和输出到什么地方，它本质就是一个无状态处理数据的工具，所以框架可以处理在机器之间移动数据的复杂性。

在分布式计算中，并行化基于分区，这意味着分布式批处理中的输出文件或文件快被认为是一个单独的分区。MapReduce 调度器会在其中一台存储输入文件副本的机器上运行每个Mapper。这个行为被称为**计算放在数据附近**，其实是为了节约网络复制输入文件的开销，减少网络复制并增加局部性。

计算的Reduce端也会被分区。虽然 Map 任务的数量由输入文件块的数量决定，但 Reducer 的任务的数量是由作业作者配置的。为了确保具有相同键的所有键值对最终落在相同的 Reducer 处，框架使用键的散列值来确定哪个 Reduce 任务应该接收到特定的键值对。

当Mapper读取输入文件，并写完排序后的输出文件，MapReduce调度器会通知Reducer获取输出文件。然后Reducer会按分区，排序，从 Mapper 向 Reducer 复制分区数据，这一整个过程被称为 **混洗（shuffle）**。然后将从Mapper获取的文件合并在一起，并保留有序特性，如果不同的Mapper生成了相同的键，则将它们相邻。



