---
title: AI是什么？
date: 2024-4-11 10:50:00
tags: [AI,学习笔记]
category: AI
---

### 前言

> 当一个新事物的出现，最好的办法就是了解它出现的背景，发展的历史。

当ChatGPT出现在我们面前，多轮对话能力让人震惊，仿佛机器真的可以"理解"人类语言。不同于当时Siri一样的语音助手，ChatGPT的准确率相比之下非常高。

于是一夜之间AI的浪潮袭来，时至今日各个厂商相继公开自己的大模型并不断迭代：GPT-4-Turbo,Qwen-Max，智谱清言GLM-4等。AI能力也从最初的对话型衍生出多种：图片生成，语音识别，文档解析，代码补全，视频生成，AI搜索……

当技术发生了翻天覆地的变化和革新，不管是否愿意，时代的浪潮会推着我们前进。同时技术变化也不是徐徐图之，而是剧烈革新代替。我们回头看，云原生技术的推进是如此，移动互联网时代也是如此。所以我们应该积极了解AI到底是什么，从而明白AI能做哪些，不能做哪些？它又能给我们带来哪些技术上的革命。



### ChatGPT

如果说从名称上看**Chat**代表着'聊天/对话'，那么GPT又代表着什么呢？

GPT全称为 Generative(生成式) Pre-trained(预训练) Transformer(转换器),从这三个词透露出来的信息，可以不负责的猜测一下，是不是意味着："将人类语言转换为机器能识别的信息，经过反复训练就能得到生成式的AI模型？"

事实上Transformer是一个神经网络架构，它的作用就是模仿人类的**注意力**。在现实生活中一些场景上下文是有关联的，比如一段视频是由多张图片组成，对话也有上下文作关联。将这些存在一定关联的数据做特殊处理以后，它们被称为“时序数据”或序列(sequence)，Transformer 在实际任务中就是将一个序列转换为另外一个序列。将一段中文转换为一段英文，将一个问题转换成一个回答……这就是Transformer名称的由来。

预训练代表着模型的训练方式，在神经网络训练中采用更大，更多的参数先对模型进行训练，然后再进行微调。通俗一点讲就是九年义务教育，让模型拥有一些基础的通用能力，微调则代表着某一方面的偏重技能，就像选专业一样。

ChatGPT采用基于人类反馈的强化学习(Reinforcement learning from human feedback， RLHF)来进行预训练微调。整个过程分为三步：

1.预训练一个语言模型：从优质的数据集中拿出一部分的数据，然后监督模型的训练

2.收集对比数据并训练奖励模型：输入数据和模型输出被采样，通过输出结果人工反馈输出的质量，给予模型回应或评分。

3.从第二步的数据采样中得到新的数据，使用强化学习的方式微调语言模型。

RLHF是用于训练AI的特定技术，它可以让模型更加精准，人工的干预也可以让模型显得更有"人性"。

























### 学习资源

https://hutusi.com/articles/the-history-of-neural-networks

https://www.ruanyifeng.com/blog/2017/07/neural-network.html

https://aws.amazon.com/tw/what-is/reinforcement-learning-from-human-feedback/
