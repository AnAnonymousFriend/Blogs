---
title: AI是什么？
date: 2024-4-11 10:50:00
tags: [AI,学习笔记]
category: AI
---

### 前言

> 当一个新事物的出现，最好的办法就是了解它出现的背景，发展的历史。

当ChatGPT出现在我们面前，多轮对话能力让人震惊，仿佛机器真的可以"理解"人类语言。不同于当时Siri一样的语音助手，ChatGPT的准确率相比之下非常高。

于是一夜之间AI的浪潮袭来，时至今日各个厂商相继公开自己的大模型并不断迭代：GPT-4-Turbo,Qwen-Max，智谱清言GLM-4等。AI能力也从最初的对话型衍生出多种：图片生成，语音识别，文档解析，代码补全，视频生成，AI搜索……

当技术发生了翻天覆地的变化和革新，不管是否愿意，时代的浪潮会推着我们前进。同时技术变化也不是徐徐图之，而是剧烈革新代替。我们回头看，云原生技术的推进是如此，移动互联网时代也是如此。所以我们应该积极了解AI到底是什么，从而明白AI能做哪些，不能做哪些？它又能给我们带来哪些技术上的革命。



### ChatGPT

如果说从名称上看**Chat**代表着'聊天/对话'，那么GPT又代表着什么呢？

GPT全称为 Generative(生成式) Pre-trained(预训练) Transformer(转换器),从这三个词透露出来的信息，可以不负责的猜测一下，是不是意味着："将人类语言转换为机器能识别的信息，经过反复训练就能得到生成式的AI模型？"

事实上Transformer是一个神经网络架构，它在神经网络架构中引入了**注意力**这一概念。在现实生活中一些场景上下文是有关联的，比如一段视频是由多张图片组成，对话也有上下文作关联。将这些存在一定关联的数据做特殊处理以后，它们被称为“时序数据”或序列(sequence)，Transformer 在实际任务中就是将一个序列转换为另外一个序列。将一段中文转换为一段英文，将一个问题转换成一个回答……这就是Transformer名称的由来。

预训练代表着模型的训练方式，在神经网络训练中采用更大，更多的参数先对模型进行训练，然后再进行微调。通俗一点讲就是九年义务教育，让模型拥有一些基础的通用能力，微调则代表着某一方面的偏重技能，就像选专业一样。

ChatGPT采用基于人类反馈的强化学习(Reinforcement learning from human feedback， RLHF)来进行预训练微调。整个过程分为三步：

1.预训练一个语言模型：从优质的数据集中拿出一部分的数据，然后监督模型的训练

2.收集对比数据并训练奖励模型：输入数据和模型输出被采样，通过输出结果人工反馈输出的质量，给予模型回应或评分。

3.从第二步的数据采样中得到新的数据，使用强化学习的方式微调语言模型。

RLHF是用于训练AI的特定技术，它可以让模型更加精准，人工的干预也可以让模型显得更有"人性"。同时数据集的量级也是一个重要因素，OpenAI 在训练GPT-1模型参数只有1.17亿，到了GPT-2就提高了15亿，GPT-3更是增长到了1750亿，这已经是呈倍数增长了，而到了GPT-4模型宣称有1.8万亿。

可能单纯提及数字并不能真正表达出这个量级的数据集意味着什么，对于有过写作经验的工程师来说能体会的更深一点。有一些教你如何写作的书中总会强调，多看一些别人的文章，多写点文章，这样写作能力自然就提高了。想象一下，你需要看多少本书才能写一本书？而一本二十万字的书需要写上百篇的博客文章。

> 质量问题本质是数量问题，当数量级成倍增长，那么大模型的能力也由量变转为了质变。



在简单理解了**Transformer**和**Pre-trained**之后，应该怎么理解**Generative**呢？

在GPT底层下，深度学习模型不断重新创造它们从大量训练数据中学会的模式，然后在设定的范围参数中工作，根据学到的知识在创造新的内容，这个特性被称为Generative(生成式)。

> 深度学习模型通常不会存储训练数据的副本，而是会将数据进行编码，使类似的数据点被安排在彼此附近。之后，再对这种表示进行解码，以构建具有类似特征的新原始数据。

正是因为生成式AI的创造力，让AI智能向AGI迈进了一大步。





















### 学习资源

https://hutusi.com/articles/the-history-of-neural-networks

https://www.ruanyifeng.com/blog/2017/07/neural-network.html

https://aws.amazon.com/tw/what-is/reinforcement-learning-from-human-feedback/
