---
title: 《设计数据密集形应用》第二章读书笔记
date: 2023-8-15 16:47:00
tags: [分布式,学习笔记]
category: 分布式

---

# 分布式数据

《设计数据密集型应用》一书第二部分，分布式数据中涉及到了数据的复制,如何分区，分布式事务，讨论了分布式系统的麻烦及解决方案，一致性与共识的认知。



## 复制

复制代表着通过网络连接的多台机器上保留着相同的副本。一般情况下使用复制功能，我们更期望的是：

1.让用户在地理上更接近数据(从而减少延迟)

2.系统的一部分出现故障，系统也能继续工作(提高可用性)

3.伸缩可以接受读请求的机器数量(提高吞吐量)

如果复制的数据不会随着时间而改变，那复制就变得很简单：将数据复制到每节点，仅需一次就好了。但复制的困难往往出现在处理复制数据的**变更**。

本小结将会讨论三种流行的变更复制算法：**单领导者（single leader，单主）**，**多领导者（multi leader，多主）** 和 **无领导者（leaderless，无主）**。几乎所有分布式数据库都使用这三种方法之一。

当然，在复制时也同样进行很多权衡，使用同步复制还是异步复制？如何处理失败的副本？



### 领导者与追随者

存储了数据拷贝的每个节点被称为**副本(replica)**。当多个副本存在时就有出现一个问题：如何确保所有数据都存在副本上？

每一次向数据库的写入操作都需要传播到所有副本上，否则副本数据就不能保持一致。

**基于领导者的复制（leader-based replication）** （也称 **主动/被动（active/passive）** 复制或 **主/从（master/slave）** 复制）

1.在多个副本中选一个副本指定其为**领导者(leader)**,有时也被称为**主库(master|primary)**。当客户端发送写入请求时，它必须将请求发送给**领导者**，其会将新数据写入其本地存储。

2.其他副本被称为 **追随者（followers）**，亦称为 **只读副本（read replicas）**、**从库（slaves）**、**备库（ secondaries）** 或 **热备（hot-standby）**[1](https://github.com/Vonng/ddia/blob/master/ch5.md#user-content-fn-i-8006e2d5a73957a25f1adcd45244d11b)。每当领导者将新数据写入本地存储时，它也会将数据变更发送给所有的追随者，称之为 **复制日志（replication log）** 或 **变更流（change stream）**。每个跟随者从领导者拉取日志，并相应更新其本地数据库副本，方法是按照与领导者相同的处理顺序来进行所有写入。

3.当客户想要从数据库中读取数据时，它可以向领导者或任一追随者进行查询。但只有领导者才能接受写入操作（从客户端的角度来看从库都是只读的）。

![image-20230815174416749](https://raw.githubusercontent.com/AnAnonymousFriend/images/main/image-20230815174416749.png)

#### 同步复制和异步复制

复制系统的一个重要细节是：复制是 **同步（synchronously）** 发生的还是 **异步（asynchronously）** 发生的。

通常情况下复制的速度相当快：大多数数据库系统能在一秒内完成从库的同步，但它们不能提供复制用时的保证。在某些情况下从库可能落后主库几分钟或者更久：比如从库正在从故障中恢复，系统正在最大容量附近运行，或者当节点间存在网络问题时。

同步复制的优点：从库能保证与主库一致的最新数据副本。如果主库突然失效，我们依然能在从库上找到这些数据。

同步复制的缺点：如果同步从库没有响应(比如从库已经崩溃，或者网络出现故障)，主库就无法处理写入操作。主库会阻止所有写入，一直到从库再次可用。

> 所以将所有从库都设置为同步是不切实际的。因为任何一个节点的中断都会影响到整个系统，这对高可用来说是致命的。
>
> 在现实使用场景，如果在数据库上启用同步复制，通常指其中**一个**从库是同步的，其他从库是异步的。如果该同步从库变得不可用或缓慢，则将一个异步从库改为同步运行。这保证你至少在两个节点上拥有最新的数据副本：主库和同步从库。 这种配置有时也被称为 **半同步（semi-synchronous）**。

通常情况下，基于领导者的复制都配置为完全异步。在这种情况下，如果主库失效且不可恢复，则任何尚未复制给从库的写入都会丢失。这意味着即使已经向客户端确认成功，写入也不能保证是 **持久（Durable）** 的。然而，一个完全异步的配置也有优点：即使所有的从库都落后了，主库也可以继续处理写入。



#### 设置新从库

有时候需要临时设置一个新的从库，可能是负载更大需要增加副本的数量，或者替换掉集群中长期失败的节点。

设置新从库会有如下流程：

1. 在某个时刻获取主库的一致性快照（如果可能，不必锁定整个数据库）。大多数数据库都具有这个功能，因为它是备份必需的。对于某些场景，可能需要第三方工具，例如用于 MySQL 的 innobackupex。
2. 将快照复制到新的从库节点。
3. 从库连接到主库，并拉取快照之后发生的所有数据变更。这要求快照与主库复制日志中的位置精确关联。该位置有不同的名称，例如 PostgreSQL 将其称为 **日志序列号（log sequence number，LSN）**，MySQL 将其称为 **二进制日志坐标（binlog coordinates）**。
4. 当从库处理完快照之后积累的数据变更，我们就说它 **赶上（caught up）** 了主库，现在它可以继续及时处理主库产生的数据变化了。

建立从库这个步骤需要根据不同的数据来进行配置，有些可能是自动化的，有些则需要管理手动操作。



#### 处理节点宕机

##### 从库失效：追赶恢复

在宿主机的本地磁盘中，会记录者从库收到的数据变更日志，如果从库崩溃并重新启动。从库可以从日志中得知，在发生故障之前处理的最后一个事务。因此，从库可以连接到主库，并请求在从库断开期间发生的所有数据变更。当应用完所有这些变更后，它就赶上了主库，并可以像以前一样继续接收数据变更流。

##### 主库失效：故障切换

主库失效处理起来相当棘手：其中一个从库需要被提升为新的主库，需要重新配置客户端，以将它们的写操作发送给新的主库，其他从库需要开始拉取来自新主库的数据变更。这个过程被称为 **故障切换（failover）**。

自动化切换：

1.确认主库失效。可以使用超时机制来确定主库是否挂了，类似于心跳包。

2.选举：剩余副本通过**共识算法**选举出一个新的主库。(也可以事先配置**控制节点**来指定新的主库)

3.重新配置系统以启用新的主库。如果旧主库恢复，让它成为一个从库。

> 故障自动切换过程中会相当麻烦且繁琐，不少运维团队更愿意手动执行故障切换。



#### 复制日志的实现

1.基于语句的复制

主库记录它执行的每个写入请求(语句)并将该语句日志发送给从库。每个从库解析并执行SQL语句，就像直接从客户端收到一样。

但是下列问题会让第一种实现变得数据不一致：

- 任何调用 **非确定性函数（nondeterministic）** 的语句，可能会在每个副本上生成不同的值。例如，使用 `NOW()` 获取当前日期时间，或使用 `RAND()` 获取一个随机数。
- 如果语句使用了 **自增列（auto increment）**，或者依赖于数据库中的现有数据（例如，`UPDATE ... WHERE <某些条件>`），则必须在每个副本上按照完全相同的顺序执行它们，否则可能会产生不同的效果。当有多个并发执行的事务时，这可能成为一个限制。
- 有副作用的语句（例如：触发器、存储过程、用户定义的函数）可能会在每个副本上产生不同的副作用，除非副作用是绝对确定性的。

> 通常情况下都不会选用这种复制方法



2.传输预写式日志（WAL）

- 对于日志结构存储引擎（请参阅 “[SSTables 和 LSM 树](https://github.com/Vonng/ddia/blob/master/ch3.md#SSTables和LSM树)”），日志是主要的存储位置。日志段在后台压缩，并进行垃圾回收。
- 对于覆写单个磁盘块的 [B 树](https://github.com/Vonng/ddia/blob/master/ch3.md#B树)，每次修改都会先写入 **预写式日志（Write Ahead Log, WAL）**，以便崩溃后索引可以恢复到一个一致的状态。

可以使用完全相同的日志在另一个节点上构建副本：除了将日志写入磁盘之外，主库还可以通过网络将其发送给从库。

通过使用这个日志，从库可以构建一个与主库一模一样的数据结构拷贝。

缺点：日志记录的数据非常底层，可能存在版本不兼容。会对运维团队造成麻烦。



3.逻辑日志复制(基于行)

对复制和存储引擎使用不同的日志格式，这样可以将复制日志从存储引擎的内部实现中解耦出来。这种复制日志被称为逻辑日志（logical log），以将其与存储引擎的（物理）数据表示区分开来。

关系数据库的逻辑日志通常是以行的粒度来描述对数据库表的写入记录的序列：

- 对于插入的行，日志包含所有列的新值。
- 对于删除的行，日志包含足够的信息来唯一标识被删除的行，这通常是主键，但如果表上没有主键，则需要记录所有列的旧值。
- 对于更新的行，日志包含足够的信息来唯一标识被更新的行，以及所有列的新值（或至少所有已更改的列的新值）。

> 修改多行的事务会生成多条这样的日志记录，后面跟着一条指明事务已经提交的记录。 MySQL 的二进制日志(当配置为使用基于行的复制时)使用了这种方法。



4.基于触发器的复制

有一些工具可以通过读取数据库日志，使其他应用程序可以使用数据。或者使用关系数据库自带的功能：触发器和存储过程。

触发器允许将数据更改(写入事务)发生时自动执行自定义应用程序代码注册早数据库系统中，触发器可以将更改记录到一个单独的表中，然后再使用外部应用程序读这个表，再加上一点自定义的逻辑就可以将数据复制到另一个系统中去。

基于触发器的复制通常比其他复制方法具有更高的开销，并且比数据库内置的复制更容易出错，也有很多限制。然而由于其灵活性，它仍然是很有用的。



#### 复制延迟问题

基于领导者的复制要求所有写入都由单个节点处理，但只读查询可以由任何一个副本来处理。所以对于读多写少的场景（Web 上的常见模式），一个有吸引力的选择是创建很多从库，并将读请求分散到所有的从库上去。这样能减小主库的负载，并允许由附近的副本来处理读请求。

在这种读伸缩（read-scaling）的体系结构中，只需添加更多的从库，就可以提高只读请求的服务容量。但是，这种方法实际上只适用于异步复制 —— 如果尝试同步复制到所有从库，则单个节点故障或网络中断将导致整个系统都无法写入。而且节点越多越有可能出现个别节点宕机的情况，所以完全同步的配置将是非常不可靠的。

但是异步会有一个问题，如果从库落后，会导致在某一个时间段存在数据不一致的问题。在正常操作中，**复制延迟**在实际中并不显眼，但是在极端情况下延迟会在几秒到几分钟钟不等。

这会造成三种情况：



1.读已之写

如果用户写入后马上查看数据，新数据可能没来得及到达副本，对于用户而言，看起来好像是刚提交的数据丢失了。

在这种情况下，我们需要 **写后读一致性（read-after-write consistency）**，也称为 **读己之写一致性（read-your-writes consistency）**。这是一个保证，如果用户重新加载页面，他们总会看到他们自己提交的任何更新。它不会对其他用户的写入做出承诺：其他用户的更新可能稍等才会看到。它保证用户自己的输入已被正确保存。

如何在基于领导者的复制系统中实现写后读一致性？文中提供了几种解决：

1.1对于**可能用户修改过**的内容，总是从主库读取。这就要求得有办法不通过实际的查询就可以知道用户是否修改了某些东西。例如：总是从主库读取用户自己的档案，如果要读取其他用户的档案就去从库。

1.2通过跟踪上次更新时间，在上次更新后的一分钟内从主库读。还可以监控从库的复制延迟，防止向任何滞后主库超过一分钟的从库发出查询。

1.3客户端记录最近一次写入的时间戳，系统需要确保从库在处理该用户的读取请求时，该时间戳前的变更都已经传播到了本从库中。如果当前从库不够新，则可以从另一个从库读取，或者等待从库追赶上来。但是使用这个方法的时候要注意：**时钟同步变得至关重要**。

> 但是这种情况下记住用户上次更新时间戳的方法变得更加困难，因为一个设备上运行的程序不知道另一个设备上发生了什么。需要对这些元数据进行中心化的存储。



1.4如果副本分布在多个数据中心，还会变得更加复杂，因为任何需要主库提供服务的请求都必须路由到包含主库的数据中心。

> 如果副本分布在不同的数据中心，很难保证来自不同设备的连接会路由到同一数据中心。



2.单调读

如果先查询了一个延迟很小的从库，然后再查询一个延迟较大的从库。(数据可能也会存在差异，延迟较小的从库上存在，延迟较大的从库上可能不存在)这会让用户非常疑惑。

**单调读（monotonic reads）**可以保证这种异常不会发生。这是一个比 **强一致性（strong consistency）** 更弱，但比 **最终一致性（eventual consistency）** 更强的保证。当读取数据时，你可能会看到一个旧值；单调读仅意味着如果一个用户顺序地进行多次读取，则他们不会看到时间回退，也就是说，如果已经读取到较新的数据，后续的读取不会得到更旧的数据。

实现单调读的一种方式是确保每个用户总是从同一个副本进行读取（不同的用户可以从不同的副本读取）。例如，可以基于用户 ID 的散列来选择副本，而不是随机选择副本。但是，如果该副本出现故障，用户的查询将需要重新路由到另一个副本。

要防止某些分区的复制速度慢于其他分区造成的异常状态，需要另一种类型保证：**一致前缀读（consistent prefix reads）**，如果一系列写入按某个顺序发生，那么任何人读取这些写入时，也会看见它们以同样的顺序出现。

一种解决方案是，确保任何因果相关的写入都写入相同的分区，但在一些应用中可能无法高效地完成这种操作。



复制延迟最终解决方案：

- 在应用程序出做处理，但是容易出错且复杂。
- 使用分布式事务，但是不是所有数据库都支持。



### 多主复制

基于领导者的复制有一个主要的缺点：只有一个主库，而且所有的写入都必须通过它 [4](https://github.com/Vonng/ddia/blob/master/ch5.md#user-content-fn-iv-8006e2d5a73957a25f1adcd45244d11b)。如果出于任何原因（例如和主库之间的网络连接中断）无法连接到主库， 就无法向数据库写入。

基于领导者的复制模型的自然延伸是允许多个节点接受写入。复制仍然以同样的方式发生：处理写入的每个节点都必须将该数据变更转发给所有其他节点。我们将其称之为 **多领导者配置**（multi-leader configuration，也称多主、多活复制，即 master-master replication 或 active/active replication）。在这种情况下，每个主库同时是其他主库的从库。



#### 多主复制的应用场景

单个数据中心使用多个主库的配置没有什么意义，复杂性已经超过了能带来的好处。

假设你有一个数据库，副本分散在好几个不同的数据中心，如果使用常规的基于领导者的复制设置，主库必须位于其中一个数据中心，且所有写入都必须经过该数据中心。

但是如果使用多主配置，这样每个数据中心都有一个主库。在每个数据中心内使用常规的主从复制；在数据中心之间，每个数据中心的主库都会将其更改复制到其他数据中心的主库中。

多主配置的优点：

1.在多个数据中心的情况下，多主配置的性能可能要好于单主配置。

2.在多主配置中，每个数据中心可以独立于其他数据中心继续运行，并且当发生故障的数据中心归队时，复制会自动赶上。从这一点来说多主配置的可用性要高于单主配置。

3.采用异步复制功能的多主配置通常能更好地承受网络问题：临时的网络中断并不会妨碍正在处理的写入。

缺点：

1.**两个不同的数据中心可能会同时修改相同的数据，写冲突是必须解决的。**

2.由于多主复制在许多数据库中都属于改装的功能，所以常常存在微妙的配置缺陷，且经常与其他数据库功能之间出现意外的反应。比如自增主键、触发器、完整性约束等都可能会有麻烦。因此，多主复制往往被认为是危险的领域，应尽可能避免。



**多主复制的另一种适用场景是：应用程序在断网之后仍然需要继续工作。**

在这种情况下，每个设备都有一个充当主库的本地数据库（它接受写请求），并且在所有设备上的日历副本之间同步时，存在异步的多主复制过程。复制延迟可能是几小时甚至几天，具体取决于何时可以访问互联网。

从架构的角度来看，这种设置实际上与数据中心之间的多主复制类似，每个设备都是一个 “数据中心”，而它们之间的网络连接是极度不可靠的。从历史上各类日历同步功能的破烂实现可以看出，想把多主复制用好是多么困难的一件事。



**协同编辑场景下也适合**

当一个用户编辑文档时，所做的更改将立即应用到其本地副本（Web 浏览器或客户端应用程序中的文档状态），并异步复制到服务器和编辑同一文档的任何其他用户。

但是依旧要保证不会发生编辑冲突的问题，还需要应用文档的锁，然后用户才能对其编辑。如果另一个用户想要编辑同一个文档，他们首先必须等到第一个用户提交修改并释放锁定。这种协作模式相当于主从复制模型下在主节点上执行事务操作。



#### 处理写入冲突

多主复制的最大问题是可能发生写冲突，这意味着需要解决冲突。

原则上，可以使冲突检测同步 - 即等待写入被复制到所有副本，然后再告诉用户写入成功。但是，通过这样做，你将失去多主复制的主要优点：允许每个副本独立地接受写入。如果你想要同步冲突检测，那么你可能不如直接使用单主复制。

解决方案：

1.避免冲突，如果应用程序可以确保特定记录的所有写入都通过同一个主库，那么冲突就不会发生。例如，在一个用户可以编辑自己数据的应用程序中，可以确保来自特定用户的请求始终路由到同一数据中心，并使用该数据中心的主库进行读写。不同的用户可能有不同的 “主” 数据中心（可能根据用户的地理位置选择），但从任何一位用户的角度来看，本质上就是单主配置了。

> 但是也会出现另一种情况：因为某个数据中心出现故障，需要将流量重新路由到另一个数据中心，在这种情况下，无法避免冲突。必须处理不同主库同时写入的可能性。

2.收敛至一致的状态，这意味着所有副本必须在所有变更复制完成时**收敛**至一个相同的最终值。

- 给每个写入一个唯一的 ID（例如时间戳、长随机数、UUID 或者键和值的哈希），挑选最高 ID 的写入作为胜利者，并丢弃其他写入。如果使用时间戳，这种技术被称为 **最后写入胜利（LWW, last write wins）**。虽然这种方法很流行，但是很容易造成数据丢失。
- 为每个副本分配一个唯一的 ID，ID 编号更高的写入具有更高的优先级。这种方法也意味着数据丢失。
- 以某种方式将这些值合并在一起 - 例如，按字母顺序排序，然后连接它们。
- 用一种可保留所有信息的显式数据结构来记录冲突，并编写解决冲突的应用程序代码（也许通过提示用户的方式，类似Git？）。



解决冲突的最合适的方法可能取决于应用程序：

写时执行：只要数据库检测到复制更改日志中存在冲突，就调用冲突处理程序。

读时执行：当检测到冲突时，所有冲突写入被存储。下一次读取数据时，会将这些多个版本的数据返回给应用程序。应用程序可以提示用户或自动解决冲突，并将结果写回数据库。

> 自动冲突解决会随着时间推移变得越来越复杂，自定义的代码也可能出错。
