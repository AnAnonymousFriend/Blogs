---
title: 如何构建一个RAG应用？
date: 2024-6-8 21:15:00
tags: [AI,RAG]
category: AI
---

### RAG概述

Retrieval Augmented Generation RAG 检索增强的内容生成。

从字面上来看，检索只是一种手段，在人工智能领域中存在多种增强大语言模型输出的手段，而检索只是其中一种。不同于传统应用的检索，RAG中的检索更像是大语言模型能力的扩展，它的侧重点在于如何通过检索出来的信息，让大模型生成出更优质的内容，这个过程被称为Augmented。

为什么大语言模型的输出会需要增强呢？

现阶段大语言模型在训练时会接触到大量文本数据，这些文本数据可能包括书籍，网页，论文，新闻资讯等信息。这些数据构成了模型对现实世界的基础理解，模型信息中会特地标注训练时所使用的参数量(Billion)，7B 代表着 70亿个训练参数。优质的内容和训练参数的数量级都会影响模型的能力和输出质量，但知识库的构建会基于某个时间点的数据，模型的训练也可能在之后的时间完成，这带来不可避免的滞后性和时效性。

通过检索最新的数据作为上下文提示，能在一定程度上弥补语言模型在知识更新方面的不足，可以提供更加准确的回答。但它的效果也依赖检索系统和知识库的质量。私域场景下，大模型在理解私域文档后结合它自己知识库所产生的输出，要比传统私域文档中做检索要优质得多。



### 过程概述

构建一个RAG大概分为三个部分：1.为私域数据建立索引(Embedding) 2.基于用户的输入，将相似度最高的内容的提取出来(向量搜索) 3.基于用户的问题，对回答的内容进行增强(提示词工程)。

[过程概述图]

```python
from langchain.document_loaders import WebBaseLoader
from langchain.indexes import VectorstoreIndexCreator
loader = WebBaseLoader("http://www.paulgraham.com/greatwork.htm	l")
index = VectorstoreIndexCreator().from_loaders([loader])
index.query("What should I work on?")
```



检索本质上是一种搜索操作，传统的搜索引擎可以根据用户的输入查找最相关的信息。在AI检索中的行为也是类似的，但它由两个部分组成：

1.索引：将知识库变为可以搜索/查询的内容。

2.查询：从搜索词中提取最相关的知识。

任何搜索过程都可以用于检索，可以把检索当作一个外部扩展的工具，无论是通过Restful API 还是通过向量搜索，只要能检索出输出问题想匹配的信息，满足相关的上下文输出给大模型，那么这个检索过程就是符合要求的。

建立索引的过程也是Embedding的过程，因为模型会有上下文的限制，通常情况下建立私域知识库时会先将文档进行“切片”。切片对于RAG是一个很重要的部分，如果一个将一个大文档直接输入给大语言模型，根本没什么意义。如果切的太小也会造成输出质量的下降——相关性内容会丢失。

开发时，这里需要做一个权衡，切成什么大小才能更接近一个平衡点。LangChain 可能已经提供了工具来解决这一问题(待验证)。但不同的文档和内容不能一概而论，需要通过具体的场景做权衡。

索引是构建整个RAG最困难和最重要的部分，索引过程可以分为两个高级步骤：

1.加载：从通常存储的位置获取知识库的内容

2.分割：将知识库分割成适合嵌入搜索的片段大小的块。

"适合"这个词在软件工程中让人感觉格格不入，到底什么是适合？这句话和食谱中的“适量”有着相同的迷惑性，在历经传统应用开发的洗礼后，在做AI应用时存在的各种不确定性。将用户输入的问题和一大堆的提示词结合在一起，将它们向量化后在另外一堆向量数据中进行匹配，最终输出给一个黑盒。企图它能输出优质内容，这更像是《计算机程序的构造和解释》前言中形容的魔法。

但它真的能运行。















### 学习资料

[How do domain-specific chatbots work? An Overview of Retrieval Augmented Generation (RAG)](https://scriv.ai/guides/retrieval-augmented-generation-overview)
