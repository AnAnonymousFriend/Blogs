---
title: 《设计数据密集形应用》读书笔记
date: 2023-8-3 18:05:00
tags: [分布式,学习笔记]
category: 分布式

---



《设计数据密集应用》分为三个部分，数据系统基础;分布式数据;衍生数据；每部分包含若干章节，本文为DDIA读书笔记，包含作者阅读记录，仅用于作者本人学习记录，如有理解歧义，误区等以原书为准。

# 数据系统基础

## 可靠性,可伸缩性和可维护性

本书开篇讲述了作为一个**计算密集形**的应用需要什么？

一个数据密集的应用程序，通常会包含若干组件，有经验的工程师通常会优先设计**数据存储方式**用于存储数据，这代表持久化。但随着技术的不断发展，某些应用也可以不使用传统的数据库实现持久化。（比如笔者见过某些应用在云原生中使用ConfigMap进行数据存储）

考虑持久化后不可避免地涉及到数据库的选型（是选择关系性还是非关系型数据库），或者是复杂查询场景下昂贵开销使得应用响应变慢，引入**缓存机制**。亦或者是为了优化用户体验，允许用户通过关键字搜索数据，过滤等，接入**搜索索引**。为了避免页面响应过长采用**异步处理**，还是为了定期处理，清洗大批量数据引入的**批处理**。

这些机制已经被**数据系统**很好抽象成为某些数据库某个特点了，但是现实中的场景往往比上述要复杂百倍，不同的数据库系统也有不同的特性。当为了实现某个复杂应用时，不得不组合使用这些工具，这还是有些难度的。

所以第一部分我们需要了解数据系统的共性与特性，及各自实现的原理。

第一章的目标就是为了弄懂：什么是可靠，可伸缩，可维护的数据系统是什么样的。



### 可靠性

人们总是希望自己使用的工具是**可靠的**，对于软件也有同样直观的想法。比如在使用一个搜索引擎，当你输入关键词后，理所应当地会对查询结果有一个心理预期，并期望它能返回符合预期的答案或结果。

同时人们总是对软件有更高的期许：希望即使不按照正常流程操作，它也不会崩溃；希望它的性能足够好，允许在一定负载下也能良好运行。

工程师们都在追求应用程序的容错性，但是绝对不能容忍因为**故障**而导致的**失效**。而故障又分为几种情况：

1.硬件故障：硬盘崩溃，内存出错，机房断电，网线磨损...这些基础的，物理的设备出现故障时给应用程序的打击几乎是毁灭的。当设备足够多时，这些情况总有一天会出现的。为了减少系统的故障率，第一反应通常都是增加单个硬件的冗余度，因为硬件的故障有可能是不可逆的，只要你能快速地把备份恢复到新机器上，故障停机时间对大多数应用而言都算不上灾难性的。只有少量高可用性至关重要的应用才会要求有多套硬件冗余。

> 对于云平台来说，灵活性和弹性是最优先的，单机可靠显得并不是那么重要。如果出现硬件故障，云平台可以快速创建出新的实例并将备份恢复到机器上，从而增强应用的可靠性。

2.软件故障：通常情况下我们认为，**系统性错误**是难以意料的，比如Linux 内核错误，比如开源组件的Bug（或彩蛋）。这种系统故障只有在异常情况下触发时才会发现，但发现时可能应用程序已经失效了。对于软件故障只能通过：测试，进程隔离，允许进程崩溃并重启（容器化），测压等方式降低它出现的几率。

3.人为错误：人为因素导致的应用程序可靠性太常见了，运维配置错误是导致服务中断的首要原因，而硬件故障（服务器或网络）仅导致了 10-25% 的服务中断。作者本人就曾在运维时误删生产环境两千条数据，人类也是不可靠的。在DDIA中总结出以下几种方法来降低人为错误的出现几率：

- 以最小化犯错机会的方式设计系统。例如，精心设计的抽象、API 和管理后台使做对事情更容易，搞砸事情更困难。但如果接口限制太多，人们就会忽略它们的好处而想办法绕开。很难正确把握这种微妙的平衡。
- 将人们最容易犯错的地方与可能导致失效的地方 **解耦（decouple）**。特别是提供一个功能齐全的非生产环境 **沙箱（sandbox）**，使人们可以在不影响真实用户的情况下，使用真实数据安全地探索和实验。
- 在各个层次进行彻底的测试，从单元测试、全系统集成测试到手动测试。自动化测试易于理解，已经被广泛使用，特别适合用来覆盖正常情况中少见的 **边缘场景（corner case）**。
- 允许从人为错误中简单快速地恢复，以最大限度地减少失效情况带来的影响。 例如，快速回滚配置变更，分批发布新代码（以便任何意外错误只影响一小部分用户），并提供数据重算工具（以备旧的计算出错）。
- 配置详细和明确的监控，比如性能指标和错误率。 在其他工程学科中这指的是 **遥测（telemetry）**（一旦火箭离开了地面，遥测技术对于跟踪发生的事情和理解失败是至关重要的）。监控可以向我们发出预警信号，并允许我们检查是否有任何地方违反了假设和约束。当出现问题时，指标数据对于问题诊断是非常宝贵的。
- 良好的管理实践与充分的培训 —— 一个复杂而重要的方面，但超出了本书的范围。



### 可伸缩性

一个系统今天能可靠运行并不代表未来一直能可靠运行。对于商业软件来说，随着用户人数的不断增多面临的挑战也就越多，并发量的快速增长，处理数据的量级变大。

**可伸缩性**用来描述系统应对负载增长能力的术语。但是在谈论可伸缩性之前，我们要明白（或至少正确了解）负载和性能到底是什么。

#### **描述负载**

负载可以使用**负载参数**数字来描述，每秒向Web服务器发出的请求、数据库中的读写比率、同时活跃的用户数量、缓存命中率或其他东西。在某些情况下，高流量网站的请求数可能超过每秒数万次甚至更多。对于普通的中小型网站，每秒数百到数千次的请求数是比较典型的范围。

#### 描述性能

1.增加负载参数并保持系统资源（CPU、内存、网络带宽等）不变时，系统性能将受到什么影响？

2.增加负载参数并希望保持性能不变时，需要增加多少系统资源？

吞吐量**（throughput）**即每秒可以处理的记录数量，或者在特定规模数据集上运行作业的总时间。对于在线系统，通常更重要的是服务的 **响应时间（response time）**，即客户端发送请求到接收响应之间的时间。

现在我们来通俗翻译刚才的两个问题：

1.当增加负载时系统资源不变，那么响应时间会变长吗？

答案是：会

2.当增加负载的同时希望响应时间不变长，需要增加多少系统资源(内存等物理资源)？

带着这两个问题我们继续讨论响应时间。

即使不断重复发送同样的请求，每次得到的响应时间也都会略有不同。现实世界的系统会处理各式各样的请求，响应时间可能会有很大差异。因此我们需要将响应时间视为一个可以测量的数值 **分布（distribution）**，而不是单个数值。

我们直接忽略平均响应时间，它并不是一个非常好的指标，因为它不能告诉你有多少用户实际上经历了这个延迟。通常使用 **百分位点（percentiles）** 会更好。如果将响应时间列表按最快到最慢排序，那么 **中位数（median）** 就在正中间：举个例子，如果你的响应时间中位数是 200 毫秒，这意味着一半请求的返回时间少于 200 毫秒，另一半比这个要长。

为了弄清异常值有多糟糕，可以看看更高的百分位点，例如第 95、99 和 99.9 百分位点（缩写为 p95，p99 和 p999）。它们意味着 95%、99% 或 99.9% 的请求响应时间要比该阈值快，例如：如果第 95 百分位点响应时间是 1.5 秒，则意味着 100 个请求中的 95 个响应时间快于 1.5 秒，而 100 个请求中的 5 个响应时间超过 1.5 秒。

响应时间的高百分位点（也称为 **尾部延迟**，即 **tail latencies**）非常重要，因为它们直接影响用户的服务体验。请求响应最慢的客户往往也是数据最多的用户，这代表他们在系统中投入更多的成本。

百分位点通常用于 **服务级别目标（SLO, service level objectives）** 和 **服务级别协议（SLA, service level agreements）**，即定义服务预期性能和可用性的合同。 SLA 可能会声明，如果服务响应时间的中位数小于 200 毫秒，且 99.9 百分位点低于 1 秒，则认为服务工作正常（如果响应时间更长，就认为服务不达标）。这些指标为客户设定了期望值，并允许客户在 SLA 未达标的情况下要求退款。

**排队延迟（queueing delay）** 通常占了高百分位点处响应时间的很大一部分。由于服务器只能并行处理少量的事务（如受其 CPU 核数的限制），所以只要有少量缓慢的请求就能阻碍后续请求的处理，这种效应有时被称为 **头部阻塞（head-of-line blocking）** 。即使后续请求在服务器上处理的非常迅速，由于需要等待先前请求完成，客户端最终看到的是缓慢的总体响应时间。因为存在这种效应，测量客户端的响应时间非常重要。

> #### 实践中的百分位点
>
> 在多重调用的后端服务里，高百分位数变得特别重要。即使并行调用，最终用户请求仍然需要等待最慢的并行调用完成。如 [图 1-5](https://github.com/Vonng/ddia/blob/master/img/fig1-5.png) 所示，只需要一个缓慢的调用就可以使整个最终用户请求变慢。即使只有一小部分后端调用速度较慢，如果最终用户请求需要多个后端调用，则获得较慢调用的机会也会增加，因此较高比例的最终用户请求速度会变慢（效果称为尾部延迟放大）

#### 应对负载的方法

通过上述一系列性能指标和负载参数，现在我们可以讨论：当负载参数增加时，如何保持良好的性能？

改架构可能是其中一个方案，显而易见低负载的架构没办法应付高负载。人们常常讨论**纵向伸缩**（垂直伸缩，使用更大的内存，更强大的物理服务器来应对高负载）和 **横向伸缩**（使用更多的小型物理机，将负载均匀分布在上面）。

还有一种方法是**弹性伸缩**，检测到负载增加时自动增加计算资源。当然也可以人为去进行手动伸缩，这会让意外操作更少一点。

> 比如博客园就曾经利用弹性伸缩抢注云实例，但也可能因为云实例被消耗殆尽而抢注失败，当负载增加时导致部分用户访问失败。

跨多台机器部署 **无状态服务（stateless services）** 非常简单，但将带状态的数据系统从单节点变为分布式配置则可能引入许多额外复杂度。出于这个原因，常识告诉我们应该将数据库放在单个节点上（纵向伸缩），直到伸缩成本或可用性需求迫使其改为分布式。

随着分布式系统的工具和抽象越来越好，至少对于某些类型的应用而言，这种常识可能会改变。可以预见分布式数据系统将成为未来的默认设置，即使对不处理大量数据或流量的场景也如此。



### 可维护性

大部分的软件不是随着开发周期结束而结束，而是在不断修复漏洞，版本更替，新功能新特性的开发中周而复始。有过开发经验的工程师通常不喜欢维护前人**遗留**下来的系统，因为这代表着可能有你来偿还技术债务，修复bug，调整架构……

更有经验的工程师会在系统设计之初就特别关注设计的三个原则：

1.可操作性：便于运维团队保持系统平稳运行。

为了便于运维团队操作，往往需要引入更多的工具，比如监控系统的运行状况，跟踪问题，建立部署、配置、管理方面的良好实践，编写相应工具。考虑平台迁移，平台的扩展等。



2.简单性：从系统中消除尽可能多的 **复杂度（complexity）**，使新工程师也能轻松理解系统。

用于消除 **额外复杂度** 的最好工具之一是 **抽象（abstraction）**。一个好的抽象可以将大量实现细节隐藏在一个干净，简单易懂的外观下面。一个好的抽象也可以广泛用于各类不同应用。比起重复造很多轮子，重用抽象不仅更有效率，而且有助于开发高质量的软件。抽象组件的质量改进将使所有使用它的应用受益。



3.可演化性：使工程师在未来能轻松地对系统进行更改，当需求变化时为新应用场景做适配。也称为 **可扩展性（extensibility）**、**可修改性（modifiability）** 或 **可塑性（plasticity）**。

可以参考Kubernetes 的设计方式，在最初就考虑到了插件的集成和扩展性。



### 本章小结

**可靠性（Reliability）** 意味着即使发生故障，系统也能正常工作。故障可能发生在硬件（通常是随机的和不相关的）、软件（通常是系统性的 Bug，很难处理）和人类（不可避免地时不时出错）。 **容错技术** 可以对终端用户隐藏某些类型的故障。

**可伸缩性（Scalability）** 意味着即使在负载增加的情况下也有保持性能的策略。为了讨论可伸缩性，我们首先需要定量描述负载和性能的方法。我们简要了解了推特主页时间线的例子，介绍描述负载的方法，并将响应时间百分位点作为衡量性能的一种方式。在可伸缩的系统中可以添加 **处理容量（processing capacity）** 以在高负载下保持可靠。

**可维护性（Maintainability）** 有许多方面，但实质上是关于工程师和运维团队的生活质量的。良好的抽象可以帮助降低复杂度，并使系统易于修改和适应新的应用场景。良好的可操作性意味着对系统的健康状态具有良好的可见性，并拥有有效的管理手段。



## 数据模型与查询语言

数据模型可能是开发中最重要的部分，它们不仅影响软件的编写方式，而且影响我们的**解题思路。**

大部分应用程序都使用层层叠加的数据模型构建。数据结构和通用数据模型来表示现实世界中的各个对象，比如金钱，货物，组织，人员等信息。

数据模型种类繁多，每个数据模型特性都不尽相同，有些用法很容易，有些则不支持如此；有些操作运行很快，有些则表现很差；有些数据转换非常自然，有些则很麻烦。

第二章中我们探讨主流的数据模型，对**关系模型,文档模型和少量基于图形的数据模型**进行分析，同时还将各种查询语言并比较它们的用例。



### 关系性模型与文档模型

最著名的数据模型可能是SQL。它基于关系模型：数据被组织成**关系（SQL中称为表）**，其中每个关系的是**元祖（SQL中称行）**的无序集合。

如今网上的大部分内容依旧是由关系性数据库来提供支持，它在互联网的各个领域中都占据主导地位。

**NoSQL**试图推翻关系模型的统治地位，如今它被重新解释为：不仅是SQL(Not Only SQL)。使用NoSQL数据库通常会有几个原因：

- 需要比关系数据库更好的可伸缩性，包括非常大的数据集或非常高的写入吞吐量
- 免费开源
- 关系模型中不能很好支持一些特殊的查询操作，期望在NoSQL中更容易的实现它
- 期望一些具有多动态性与表现力的数据模型

当然不同的应用程序存在不同的需求，数据模型也没有万金油，作者本人也赞成书中对于未来数据模型的判断：**在可预见的未来，关系数据库似乎可能会继续与各种非关系数据库一起使用 - 这种想法有时也被称为 混合持久化（polyglot persistence）。**



#### 对象关系不匹配

目前大多数应用程序开发都使用面向对象的编程语言来开发，这导致了对 SQL 数据模型的普遍批评：如果数据存储在关系表中，那么需要一个笨拙的转换层，处于应用程序代码中的对象和表，行，列的数据库模型之间。模型之间的不连贯有时被称为 **阻抗不匹配（impedance mismatch）**。

有经验的工程师会使用**对象关系映射（ORM object-relational mapping）**框架，虽然能减少转换层所需的样板代码数量，但是不能完全隐藏两个模型之间的差异。

在《设计数据密集型应用》一书中使用关系性模型做了一个例子来表现简历:

Users table:

| user_id | first_name | last_name | summary                  |
| ------- | ---------- | --------- | ------------------------ |
| 255     | Bill       | Gates     | Co-chair of ... blogger. |
|         |            |           |                          |

Regions table

| region_id | region_name         |
| --------- | ------------------- |
| 255       | Greater Boston Area |

```go
type Users struct {
	UserId    int    `json:"user_id"`
	FirstName string `json:"first_name"`
	LastName  string `json:"last_name"`
	Summary   string `json:"summary"`
}

type Regions struct {
	RegionName int `json:"region_name"`
	UserId   int `json:"user_id"`
}
```

一般SQL关系性模型通过一个唯一的标识符`user_id`来标识，对User表提供外键的引用，当然后续的SQL标准中增加对结构化数据类型和XML数据的支持；允许将多值存储在单行内，并支持文档内查询和索引。JSON 数据模型也能得到多个数据库的支持。

Json模型减少了应用程序和存储层之间的阻抗不匹配，当然它也有自己问题。比如灵活性不足。Json的表现更像是一个结构清晰的树状结构。

![image-20230809160638692](https://raw.githubusercontent.com/AnAnonymousFriend/images/main/image-20230809160638692.png)

#### 多对一和多对多的关系

