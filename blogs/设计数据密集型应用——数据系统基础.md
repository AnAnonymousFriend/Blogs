

《设计数据密集应用》分为三个部分，数据系统基础;分布式数据;衍生数据；每部分包含若干章节，本文为DDIA读书笔记，包含作者阅读记录，仅用于作者本人学习记录，如有理解歧义，误区等以原书为准。

# 数据系统基础

## 可靠性,可伸缩性和可维护性

本书开篇讲述了作为一个**计算密集形**的应用需要什么？

一个数据密集的应用程序，通常会包含若干组件，有经验的工程师通常会优先设计**数据存储方式**用于存储数据，这代表持久化。但随着技术的不断发展，某些应用也可以不使用传统的数据库实现持久化。（比如笔者见过某些应用在云原生中使用ConfigMap进行数据存储）

考虑持久化后不可避免地涉及到数据库的选型（是选择关系性还是非关系型数据库），或者是复杂查询场景下昂贵开销使得应用响应变慢，引入**缓存机制**。亦或者是为了优化用户体验，允许用户通过关键字搜索数据，过滤等，接入**搜索索引**。为了避免页面响应过长采用**异步处理**，还是为了定期处理，清洗大批量数据引入的**批处理**。

这些机制已经被**数据系统**很好抽象成为某些数据库某个特点了，但是现实中的场景往往比上述要复杂百倍，不同的数据库系统也有不同的特性。当为了实现某个复杂应用时，不得不组合使用这些工具，这还是有些难度的。

所以第一部分我们需要了解数据系统的共性与特性，及各自实现的原理。

第一章的目标就是为了弄懂：什么是可靠，可伸缩，可维护的数据系统是什么样的。



### 可靠性

人们总是希望自己使用的工具是**可靠的**，对于软件也有同样直观的想法。比如在使用一个搜索引擎，当你输入关键词后，理所应当地会对查询结果有一个心理预期，并期望它能返回符合预期的答案或结果。

同时人们总是对软件有更高的期许：希望即使不按照正常流程操作，它也不会崩溃；希望它的性能足够好，允许在一定负载下也能良好运行。

工程师们都在追求应用程序的容错性，但是绝对不能容忍因为**故障**而导致的**失效**。而故障又分为几种情况：

1.硬件故障：硬盘崩溃，内存出错，机房断电，网线磨损...这些基础的，物理的设备出现故障时给应用程序的打击几乎是毁灭的。当设备足够多时，这些情况总有一天会出现的。为了减少系统的故障率，第一反应通常都是增加单个硬件的冗余度，因为硬件的故障有可能是不可逆的，只要你能快速地把备份恢复到新机器上，故障停机时间对大多数应用而言都算不上灾难性的。只有少量高可用性至关重要的应用才会要求有多套硬件冗余。

> 对于云平台来说，灵活性和弹性是最优先的，单机可靠显得并不是那么重要。如果出现硬件故障，云平台可以快速创建出新的实例并将备份恢复到机器上，从而增强应用的可靠性。

2.软件故障：通常情况下我们认为，**系统性错误**是难以意料的，比如Linux 内核错误，比如开源组件的Bug（或彩蛋）。这种系统故障只有在异常情况下触发时才会发现，但发现时可能应用程序已经失效了。对于软件故障只能通过：测试，进程隔离，允许进程崩溃并重启（容器化），测压等方式降低它出现的几率。

3.人为错误：人为因素导致的应用程序可靠性太常见了，运维配置错误是导致服务中断的首要原因，而硬件故障（服务器或网络）仅导致了 10-25% 的服务中断。作者本人就曾在运维时误删生产环境两千条数据，人类也是不可靠的。在DDIA中总结出以下几种方法来降低人为错误的出现几率：

- 以最小化犯错机会的方式设计系统。例如，精心设计的抽象、API 和管理后台使做对事情更容易，搞砸事情更困难。但如果接口限制太多，人们就会忽略它们的好处而想办法绕开。很难正确把握这种微妙的平衡。
- 将人们最容易犯错的地方与可能导致失效的地方 **解耦（decouple）**。特别是提供一个功能齐全的非生产环境 **沙箱（sandbox）**，使人们可以在不影响真实用户的情况下，使用真实数据安全地探索和实验。
- 在各个层次进行彻底的测试，从单元测试、全系统集成测试到手动测试。自动化测试易于理解，已经被广泛使用，特别适合用来覆盖正常情况中少见的 **边缘场景（corner case）**。
- 允许从人为错误中简单快速地恢复，以最大限度地减少失效情况带来的影响。 例如，快速回滚配置变更，分批发布新代码（以便任何意外错误只影响一小部分用户），并提供数据重算工具（以备旧的计算出错）。
- 配置详细和明确的监控，比如性能指标和错误率。 在其他工程学科中这指的是 **遥测（telemetry）**（一旦火箭离开了地面，遥测技术对于跟踪发生的事情和理解失败是至关重要的）。监控可以向我们发出预警信号，并允许我们检查是否有任何地方违反了假设和约束。当出现问题时，指标数据对于问题诊断是非常宝贵的。
- 良好的管理实践与充分的培训 —— 一个复杂而重要的方面，但超出了本书的范围。



### 可伸缩性

一个系统今天能可靠运行并不代表未来一直能可靠运行。对于商业软件来说，随着用户人数的不断增多面临的挑战也就越多，并发量的快速增长，处理数据的量级变大。

**可伸缩性**用来描述系统应对负载增长能力的术语。但是在谈论可伸缩性之前，我们要明白（或至少正确了解）负载和性能到底是什么。

#### **描述负载**

负载可以使用**负载参数**数字来描述，每秒向Web服务器发出的请求、数据库中的读写比率、同时活跃的用户数量、缓存命中率或其他东西。在某些情况下，高流量网站的请求数可能超过每秒数万次甚至更多。对于普通的中小型网站，每秒数百到数千次的请求数是比较典型的范围。

#### 描述性能

1.增加负载参数并保持系统资源（CPU、内存、网络带宽等）不变时，系统性能将受到什么影响？

2.增加负载参数并希望保持性能不变时，需要增加多少系统资源？

吞吐量**（throughput）**即每秒可以处理的记录数量，或者在特定规模数据集上运行作业的总时间。对于在线系统，通常更重要的是服务的 **响应时间（response time）**，即客户端发送请求到接收响应之间的时间。

现在我们来通俗翻译刚才的两个问题：

1.当增加负载时系统资源不变，那么响应时间会变长吗？

2.当增加负载的同时希望响应时间不变长，需要增加多少系统资源(内存等物理资源)？

带着这两个问题我们继续讨论响应时间。

即使不断重复发送同样的请求，每次得到的响应时间也都会略有不同。现实世界的系统会处理各式各样的请求，响应时间可能会有很大差异。因此我们需要将响应时间视为一个可以测量的数值 **分布（distribution）**，而不是单个数值。

我们直接忽略平均响应时间，它并不是一个非常好的指标，因为它不能告诉你有多少用户实际上经历了这个延迟。通常使用 **百分位点（percentiles）** 会更好。如果将响应时间列表按最快到最慢排序，那么 **中位数（median）** 就在正中间：举个例子，如果你的响应时间中位数是 200 毫秒，这意味着一半请求的返回时间少于 200 毫秒，另一半比这个要长。

为了弄清异常值有多糟糕，可以看看更高的百分位点，例如第 95、99 和 99.9 百分位点（缩写为 p95，p99 和 p999）。它们意味着 95%、99% 或 99.9% 的请求响应时间要比该阈值快，例如：如果第 95 百分位点响应时间是 1.5 秒，则意味着 100 个请求中的 95 个响应时间快于 1.5 秒，而 100 个请求中的 5 个响应时间超过 1.5 秒。

响应时间的高百分位点（也称为 **尾部延迟**，即 **tail latencies**）非常重要，因为它们直接影响用户的服务体验。请求响应最慢的客户往往也是数据最多的用户，这代表他们在系统中投入更多的成本。

百分位点通常用于 **服务级别目标（SLO, service level objectives）** 和 **服务级别协议（SLA, service level agreements）**，即定义服务预期性能和可用性的合同。 SLA 可能会声明，如果服务响应时间的中位数小于 200 毫秒，且 99.9 百分位点低于 1 秒，则认为服务工作正常（如果响应时间更长，就认为服务不达标）。这些指标为客户设定了期望值，并允许客户在 SLA 未达标的情况下要求退款。

**排队延迟（queueing delay）** 通常占了高百分位点处响应时间的很大一部分。由于服务器只能并行处理少量的事务（如受其 CPU 核数的限制），所以只要有少量缓慢的请求就能阻碍后续请求的处理，这种效应有时被称为 **头部阻塞（head-of-line blocking）** 。即使后续请求在服务器上处理的非常迅速，由于需要等待先前请求完成，客户端最终看到的是缓慢的总体响应时间。因为存在这种效应，测量客户端的响应时间非常重要。

> #### 实践中的百分位点
>
> 在多重调用的后端服务里，高百分位数变得特别重要。即使并行调用，最终用户请求仍然需要等待最慢的并行调用完成。如 [图 1-5](https://github.com/Vonng/ddia/blob/master/img/fig1-5.png) 所示，只需要一个缓慢的调用就可以使整个最终用户请求变慢。即使只有一小部分后端调用速度较慢，如果最终用户请求需要多个后端调用，则获得较慢调用的机会也会增加，因此较高比例的最终用户请求速度会变慢（效果称为尾部延迟放大）



#### 应对负载的方法

通过上述一系列性能指标和负载参数，现在我们可以讨论：当负载参数增加时，如何保持良好的性能？

改架构可能是其中一个方案，显而易见低负载的架构没办法应付高负载。人们常常讨论**纵向伸缩**（垂直伸缩，使用更大的内存，更强大的物理服务器来应对高负载）和 **横向伸缩**（使用更多的小型物理机，将负载均匀分布在上面）。

还有一种方法是**弹性伸缩**，检测到负载增加时自动增加计算资源。当然也可以人为去进行手动伸缩，这会让意外操作更少一点。

> 比如博客园就曾经利用弹性伸缩抢注云实例，但也可能因为云实例被消耗殆尽而抢注失败，当负载增加时导致部分用户访问失败。

跨多台机器部署 **无状态服务（stateless services）** 非常简单，但将带状态的数据系统从单节点变为分布式配置则可能引入许多额外复杂度。出于这个原因，常识告诉我们应该将数据库放在单个节点上（纵向伸缩），直到伸缩成本或可用性需求迫使其改为分布式。

随着分布式系统的工具和抽象越来越好，至少对于某些类型的应用而言，这种常识可能会改变。可以预见分布式数据系统将成为未来的默认设置，即使对不处理大量数据或流量的场景也如此。